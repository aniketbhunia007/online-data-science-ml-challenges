{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MachineHack-The-Great-Indian-Hiring-Challenge.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyObFUKG4SMWl8l0OiK1vBHI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bilalProgTech/online-data-science-ml-challenges/blob/master/MachineHack-The-Great-Indian-Hiring-Challenge/Solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9E98O5Fi7gd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b1efbdc-d7a9-4b2e-cb94-8b370d5296be"
      },
      "source": [
        "!wget https://machinehack-be.s3.amazonaws.com/retail_price_prediction_mega_hiring_hackathon/Participants_Data_TGIH.zip\n",
        "!unzip \\*.zip && rm *.zip "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-11-16 09:06:35--  https://machinehack-be.s3.amazonaws.com/retail_price_prediction_mega_hiring_hackathon/Participants_Data_TGIH.zip\n",
            "Resolving machinehack-be.s3.amazonaws.com (machinehack-be.s3.amazonaws.com)... 52.219.64.48\n",
            "Connecting to machinehack-be.s3.amazonaws.com (machinehack-be.s3.amazonaws.com)|52.219.64.48|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6595880 (6.3M) [application/zip]\n",
            "Saving to: ‘Participants_Data_TGIH.zip’\n",
            "\n",
            "Participants_Data_T 100%[===================>]   6.29M  2.91MB/s    in 2.2s    \n",
            "\n",
            "2020-11-16 09:06:38 (2.91 MB/s) - ‘Participants_Data_TGIH.zip’ saved [6595880/6595880]\n",
            "\n",
            "Archive:  Participants_Data_TGIH.zip\n",
            "   creating: Participants_Data_TGIH/\n",
            "  inflating: Participants_Data_TGIH/Sample Submission.csv  \n",
            "  inflating: __MACOSX/Participants_Data_TGIH/._Sample Submission.csv  \n",
            "  inflating: Participants_Data_TGIH/Test.csv  \n",
            "  inflating: __MACOSX/Participants_Data_TGIH/._Test.csv  \n",
            "  inflating: Participants_Data_TGIH/Train.csv  \n",
            "  inflating: __MACOSX/Participants_Data_TGIH/._Train.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOZ0RDprjvD6"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-OCgk_Ogjxns",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "2a81d351-527d-4357-b7a5-151629e8a541"
      },
      "source": [
        "train = pd.read_csv('/content/Participants_Data_TGIH/Train.csv')\n",
        "test = pd.read_csv('/content/Participants_Data_TGIH/Test.csv')\n",
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>InvoiceNo</th>\n",
              "      <th>StockCode</th>\n",
              "      <th>Description</th>\n",
              "      <th>Quantity</th>\n",
              "      <th>InvoiceDate</th>\n",
              "      <th>UnitPrice</th>\n",
              "      <th>CustomerID</th>\n",
              "      <th>Country</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6141</td>\n",
              "      <td>1583</td>\n",
              "      <td>144</td>\n",
              "      <td>3</td>\n",
              "      <td>2011-05-06 16:54:00</td>\n",
              "      <td>3.75</td>\n",
              "      <td>14056.0</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6349</td>\n",
              "      <td>1300</td>\n",
              "      <td>3682</td>\n",
              "      <td>6</td>\n",
              "      <td>2011-05-11 07:35:00</td>\n",
              "      <td>1.95</td>\n",
              "      <td>13098.0</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>16783</td>\n",
              "      <td>2178</td>\n",
              "      <td>1939</td>\n",
              "      <td>4</td>\n",
              "      <td>2011-11-20 13:20:00</td>\n",
              "      <td>5.95</td>\n",
              "      <td>15044.0</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>16971</td>\n",
              "      <td>2115</td>\n",
              "      <td>2983</td>\n",
              "      <td>1</td>\n",
              "      <td>2011-11-22 12:07:00</td>\n",
              "      <td>0.83</td>\n",
              "      <td>15525.0</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6080</td>\n",
              "      <td>1210</td>\n",
              "      <td>2886</td>\n",
              "      <td>12</td>\n",
              "      <td>2011-05-06 09:00:00</td>\n",
              "      <td>1.65</td>\n",
              "      <td>13952.0</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   InvoiceNo  StockCode  Description  ...  UnitPrice CustomerID  Country\n",
              "0       6141       1583          144  ...       3.75    14056.0       35\n",
              "1       6349       1300         3682  ...       1.95    13098.0       35\n",
              "2      16783       2178         1939  ...       5.95    15044.0       35\n",
              "3      16971       2115         2983  ...       0.83    15525.0       35\n",
              "4       6080       1210         2886  ...       1.65    13952.0       35\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CDJd4bS5k5us",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86c88a44-b1ef-4a8b-dcfa-1b985eb5806e"
      },
      "source": [
        "combine = train.append(test)\n",
        "combine.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(406829, 8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FbwjAdllHdo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "050c4b59-3284-4f47-9d5e-eb10b25a0843"
      },
      "source": [
        "combine['InvoiceDate'] = pd.to_datetime(combine['InvoiceDate'], format='%Y-%m-%d %H:%M:%S')\n",
        "combine.dtypes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "InvoiceNo               int64\n",
              "StockCode               int64\n",
              "Description             int64\n",
              "Quantity                int64\n",
              "InvoiceDate    datetime64[ns]\n",
              "UnitPrice             float64\n",
              "CustomerID            float64\n",
              "Country                 int64\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EOVvm-6lZ2R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "961b0e46-f503-4e98-aeaa-8646512f3888"
      },
      "source": [
        "combine['Year'] = combine['InvoiceDate'].dt.year\n",
        "combine['Month'] = combine['InvoiceDate'].dt.month\n",
        "combine['Day'] = combine['InvoiceDate'].dt.dayofweek\n",
        "combine['Hour'] = combine['InvoiceDate'].dt.hour\n",
        "combine['Minute'] = combine['InvoiceDate'].dt.minute\n",
        "combine['Second'] = combine['InvoiceDate'].dt.second\n",
        "combine.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>InvoiceNo</th>\n",
              "      <th>StockCode</th>\n",
              "      <th>Description</th>\n",
              "      <th>Quantity</th>\n",
              "      <th>InvoiceDate</th>\n",
              "      <th>UnitPrice</th>\n",
              "      <th>CustomerID</th>\n",
              "      <th>Country</th>\n",
              "      <th>Year</th>\n",
              "      <th>Month</th>\n",
              "      <th>Day</th>\n",
              "      <th>Hour</th>\n",
              "      <th>Minute</th>\n",
              "      <th>Second</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6141</td>\n",
              "      <td>1583</td>\n",
              "      <td>144</td>\n",
              "      <td>3</td>\n",
              "      <td>2011-05-06 16:54:00</td>\n",
              "      <td>3.75</td>\n",
              "      <td>14056.0</td>\n",
              "      <td>35</td>\n",
              "      <td>2011</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>16</td>\n",
              "      <td>54</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6349</td>\n",
              "      <td>1300</td>\n",
              "      <td>3682</td>\n",
              "      <td>6</td>\n",
              "      <td>2011-05-11 07:35:00</td>\n",
              "      <td>1.95</td>\n",
              "      <td>13098.0</td>\n",
              "      <td>35</td>\n",
              "      <td>2011</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>16783</td>\n",
              "      <td>2178</td>\n",
              "      <td>1939</td>\n",
              "      <td>4</td>\n",
              "      <td>2011-11-20 13:20:00</td>\n",
              "      <td>5.95</td>\n",
              "      <td>15044.0</td>\n",
              "      <td>35</td>\n",
              "      <td>2011</td>\n",
              "      <td>11</td>\n",
              "      <td>6</td>\n",
              "      <td>13</td>\n",
              "      <td>20</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>16971</td>\n",
              "      <td>2115</td>\n",
              "      <td>2983</td>\n",
              "      <td>1</td>\n",
              "      <td>2011-11-22 12:07:00</td>\n",
              "      <td>0.83</td>\n",
              "      <td>15525.0</td>\n",
              "      <td>35</td>\n",
              "      <td>2011</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6080</td>\n",
              "      <td>1210</td>\n",
              "      <td>2886</td>\n",
              "      <td>12</td>\n",
              "      <td>2011-05-06 09:00:00</td>\n",
              "      <td>1.65</td>\n",
              "      <td>13952.0</td>\n",
              "      <td>35</td>\n",
              "      <td>2011</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   InvoiceNo  StockCode  Description  Quantity  ... Day  Hour  Minute  Second\n",
              "0       6141       1583          144         3  ...   4    16      54       0\n",
              "1       6349       1300         3682         6  ...   2     7      35       0\n",
              "2      16783       2178         1939         4  ...   6    13      20       0\n",
              "3      16971       2115         2983         1  ...   1    12       7       0\n",
              "4       6080       1210         2886        12  ...   4     9       0       0\n",
              "\n",
              "[5 rows x 14 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4sxMy-ylcPn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "8ef87719-f9a4-4b81-dc70-3a1565ba66cd"
      },
      "source": [
        "combine = combine[['StockCode', 'Quantity', 'UnitPrice', 'Country', 'Year', 'Month', 'Day', 'Hour', 'Minute']]\n",
        "combine.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>StockCode</th>\n",
              "      <th>Quantity</th>\n",
              "      <th>UnitPrice</th>\n",
              "      <th>Country</th>\n",
              "      <th>Year</th>\n",
              "      <th>Month</th>\n",
              "      <th>Day</th>\n",
              "      <th>Hour</th>\n",
              "      <th>Minute</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1583</td>\n",
              "      <td>3</td>\n",
              "      <td>3.75</td>\n",
              "      <td>35</td>\n",
              "      <td>2011</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>16</td>\n",
              "      <td>54</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1300</td>\n",
              "      <td>6</td>\n",
              "      <td>1.95</td>\n",
              "      <td>35</td>\n",
              "      <td>2011</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2178</td>\n",
              "      <td>4</td>\n",
              "      <td>5.95</td>\n",
              "      <td>35</td>\n",
              "      <td>2011</td>\n",
              "      <td>11</td>\n",
              "      <td>6</td>\n",
              "      <td>13</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2115</td>\n",
              "      <td>1</td>\n",
              "      <td>0.83</td>\n",
              "      <td>35</td>\n",
              "      <td>2011</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1210</td>\n",
              "      <td>12</td>\n",
              "      <td>1.65</td>\n",
              "      <td>35</td>\n",
              "      <td>2011</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   StockCode  Quantity  UnitPrice  Country  Year  Month  Day  Hour  Minute\n",
              "0       1583         3       3.75       35  2011      5    4    16      54\n",
              "1       1300         6       1.95       35  2011      5    2     7      35\n",
              "2       2178         4       5.95       35  2011     11    6    13      20\n",
              "3       2115         1       0.83       35  2011     11    1    12       7\n",
              "4       1210        12       1.65       35  2011      5    4     9       0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_M_msulaC9n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a38e88f-2e31-4ae9-9d7b-0fac9d926a74"
      },
      "source": [
        "combine.isnull().sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "StockCode         0\n",
              "Quantity          0\n",
              "UnitPrice    122049\n",
              "Country           0\n",
              "Year              0\n",
              "Month             0\n",
              "Day               0\n",
              "Hour              0\n",
              "Minute            0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tllSHTkcaFEq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "6a61ca09-b894-424f-d19e-4d0604f2af7e"
      },
      "source": [
        "def get_weekend(row):\n",
        "    if row == 5 or row == 6:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "combine['IsWeekend'] = combine['Day'].apply(get_weekend)\n",
        "combine.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>StockCode</th>\n",
              "      <th>Quantity</th>\n",
              "      <th>UnitPrice</th>\n",
              "      <th>Country</th>\n",
              "      <th>Year</th>\n",
              "      <th>Month</th>\n",
              "      <th>Day</th>\n",
              "      <th>Hour</th>\n",
              "      <th>Minute</th>\n",
              "      <th>IsWeekend</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1583</td>\n",
              "      <td>3</td>\n",
              "      <td>3.75</td>\n",
              "      <td>35</td>\n",
              "      <td>2011</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>16</td>\n",
              "      <td>54</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1300</td>\n",
              "      <td>6</td>\n",
              "      <td>1.95</td>\n",
              "      <td>35</td>\n",
              "      <td>2011</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2178</td>\n",
              "      <td>4</td>\n",
              "      <td>5.95</td>\n",
              "      <td>35</td>\n",
              "      <td>2011</td>\n",
              "      <td>11</td>\n",
              "      <td>6</td>\n",
              "      <td>13</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2115</td>\n",
              "      <td>1</td>\n",
              "      <td>0.83</td>\n",
              "      <td>35</td>\n",
              "      <td>2011</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1210</td>\n",
              "      <td>12</td>\n",
              "      <td>1.65</td>\n",
              "      <td>35</td>\n",
              "      <td>2011</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   StockCode  Quantity  UnitPrice  Country  ...  Day  Hour  Minute  IsWeekend\n",
              "0       1583         3       3.75       35  ...    4    16      54          0\n",
              "1       1300         6       1.95       35  ...    2     7      35          0\n",
              "2       2178         4       5.95       35  ...    6    13      20          1\n",
              "3       2115         1       0.83       35  ...    1    12       7          0\n",
              "4       1210        12       1.65       35  ...    4     9       0          0\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YpZnMmxas3n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a783859-5f05-4717-c701-7b37cc2a59c1"
      },
      "source": [
        "X = combine[combine['UnitPrice'].isnull()!=True].drop(['UnitPrice'], axis=1)\n",
        "y = np.log1p(combine[combine['UnitPrice'].isnull()!=True]['UnitPrice'].reset_index(drop=True))\n",
        "\n",
        "X_test = combine[combine['UnitPrice'].isnull()==True].drop(['UnitPrice'], axis=1)\n",
        "\n",
        "X.shape, y.shape, X_test.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((284780, 9), (284780,), (122049, 9))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnveRJlnbBew",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "5864aec0-8ed2-435c-9628-8e60b3ee2aa9"
      },
      "source": [
        "X.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>StockCode</th>\n",
              "      <th>Quantity</th>\n",
              "      <th>Country</th>\n",
              "      <th>Year</th>\n",
              "      <th>Month</th>\n",
              "      <th>Day</th>\n",
              "      <th>Hour</th>\n",
              "      <th>Minute</th>\n",
              "      <th>IsWeekend</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1583</td>\n",
              "      <td>3</td>\n",
              "      <td>35</td>\n",
              "      <td>2011</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>16</td>\n",
              "      <td>54</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1300</td>\n",
              "      <td>6</td>\n",
              "      <td>35</td>\n",
              "      <td>2011</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>35</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2178</td>\n",
              "      <td>4</td>\n",
              "      <td>35</td>\n",
              "      <td>2011</td>\n",
              "      <td>11</td>\n",
              "      <td>6</td>\n",
              "      <td>13</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2115</td>\n",
              "      <td>1</td>\n",
              "      <td>35</td>\n",
              "      <td>2011</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>12</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1210</td>\n",
              "      <td>12</td>\n",
              "      <td>35</td>\n",
              "      <td>2011</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   StockCode  Quantity  Country  Year  Month  Day  Hour  Minute  IsWeekend\n",
              "0       1583         3       35  2011      5    4    16      54          0\n",
              "1       1300         6       35  2011      5    2     7      35          0\n",
              "2       2178         4       35  2011     11    6    13      20          1\n",
              "3       2115         1       35  2011     11    1    12       7          0\n",
              "4       1210        12       35  2011      5    4     9       0          0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6dLQ7fFvbYiL"
      },
      "source": [
        "from xgboost import XGBRegressor\n",
        "from lightgbm import LGBMRegressor\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, mean_squared_log_error\n",
        "from sklearn.model_selection import KFold"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2J7hZN8Tbf41",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa6bd436-a2d0-4a48-f11f-a851fae1ca57"
      },
      "source": [
        "y.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    284780.000000\n",
              "mean          1.161674\n",
              "std           0.610241\n",
              "min           0.000000\n",
              "25%           0.810930\n",
              "50%           1.081805\n",
              "75%           1.558145\n",
              "max          10.570573\n",
              "Name: UnitPrice, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ErENNXp5bpfN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcf480b3-2c94-4e00-bb05-70c39640a6fe"
      },
      "source": [
        "err = []\n",
        "y_pred_tot_lgm = []\n",
        "features = X.columns\n",
        "feature_importance_df = pd.DataFrame()\n",
        "\n",
        "fold = KFold(n_splits=15)\n",
        "i = 1\n",
        "for train_index, test_index in fold.split(X, y):\n",
        "    x_train, x_val = X.iloc[train_index], X.iloc[test_index]\n",
        "    y_train, y_val = y[train_index], y[test_index]\n",
        "    m = LGBMRegressor(boosting_type='gbdt',\n",
        "                       max_depth=5,\n",
        "                       learning_rate=0.05,\n",
        "                       n_estimators=5000,\n",
        "                       min_child_weight=0.01,\n",
        "                       colsample_bytree=0.5,\n",
        "                       random_state=1994)\n",
        "    m.fit(x_train, y_train,\n",
        "          eval_set=[(x_train,y_train),(x_val, y_val)],\n",
        "          early_stopping_rounds=200,\n",
        "          eval_metric='rmse',\n",
        "          verbose=200)\n",
        "    pred_y = m.predict(x_val)\n",
        "    \n",
        "    fold_importance_df = pd.DataFrame()\n",
        "    fold_importance_df[\"Feature\"] = features\n",
        "    fold_importance_df[\"importance\"] = m.feature_importances_\n",
        "    fold_importance_df[\"fold\"] = i + 1\n",
        "    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n",
        "    \n",
        "    print(i, \"err_lgm: \",np.sqrt(mean_squared_log_error(np.exp(pred_y), np.exp(y_val))))\n",
        "    err.append(np.sqrt(mean_squared_log_error(np.exp(pred_y), np.exp(y_val))))\n",
        "    pred_test = m.predict(X_test)\n",
        "    i = i + 1\n",
        "    y_pred_tot_lgm.append(pred_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training until validation scores don't improve for 200 rounds.\n",
            "[200]\ttraining's l2: 0.198313\ttraining's rmse: 0.445324\tvalid_1's l2: 0.198882\tvalid_1's rmse: 0.445962\n",
            "[400]\ttraining's l2: 0.181342\ttraining's rmse: 0.425843\tvalid_1's l2: 0.18276\tvalid_1's rmse: 0.427504\n",
            "[600]\ttraining's l2: 0.171432\ttraining's rmse: 0.414043\tvalid_1's l2: 0.173633\tvalid_1's rmse: 0.416692\n",
            "[800]\ttraining's l2: 0.164283\ttraining's rmse: 0.405319\tvalid_1's l2: 0.167287\tvalid_1's rmse: 0.409007\n",
            "[1000]\ttraining's l2: 0.159641\ttraining's rmse: 0.399551\tvalid_1's l2: 0.162929\tvalid_1's rmse: 0.403644\n",
            "[1200]\ttraining's l2: 0.155594\ttraining's rmse: 0.394455\tvalid_1's l2: 0.159231\tvalid_1's rmse: 0.399038\n",
            "[1400]\ttraining's l2: 0.153211\ttraining's rmse: 0.391421\tvalid_1's l2: 0.157256\tvalid_1's rmse: 0.396555\n",
            "[1600]\ttraining's l2: 0.150723\ttraining's rmse: 0.388231\tvalid_1's l2: 0.155163\tvalid_1's rmse: 0.393908\n",
            "[1800]\ttraining's l2: 0.148882\ttraining's rmse: 0.385852\tvalid_1's l2: 0.153743\tvalid_1's rmse: 0.392101\n",
            "[2000]\ttraining's l2: 0.146845\ttraining's rmse: 0.383203\tvalid_1's l2: 0.152207\tvalid_1's rmse: 0.390137\n",
            "[2200]\ttraining's l2: 0.145153\ttraining's rmse: 0.380989\tvalid_1's l2: 0.1509\tvalid_1's rmse: 0.388458\n",
            "[2400]\ttraining's l2: 0.143186\ttraining's rmse: 0.378399\tvalid_1's l2: 0.149157\tvalid_1's rmse: 0.386208\n",
            "[2600]\ttraining's l2: 0.141318\ttraining's rmse: 0.375923\tvalid_1's l2: 0.14748\tvalid_1's rmse: 0.384031\n",
            "[2800]\ttraining's l2: 0.139883\ttraining's rmse: 0.37401\tvalid_1's l2: 0.146482\tvalid_1's rmse: 0.38273\n",
            "[3000]\ttraining's l2: 0.13859\ttraining's rmse: 0.372277\tvalid_1's l2: 0.145388\tvalid_1's rmse: 0.381297\n",
            "[3200]\ttraining's l2: 0.137496\ttraining's rmse: 0.370804\tvalid_1's l2: 0.144614\tvalid_1's rmse: 0.380281\n",
            "[3400]\ttraining's l2: 0.136465\ttraining's rmse: 0.369412\tvalid_1's l2: 0.143854\tvalid_1's rmse: 0.379282\n",
            "[3600]\ttraining's l2: 0.135347\ttraining's rmse: 0.367895\tvalid_1's l2: 0.14304\tvalid_1's rmse: 0.378207\n",
            "[3800]\ttraining's l2: 0.134601\ttraining's rmse: 0.36688\tvalid_1's l2: 0.142539\tvalid_1's rmse: 0.377544\n",
            "[4000]\ttraining's l2: 0.133795\ttraining's rmse: 0.365779\tvalid_1's l2: 0.141957\tvalid_1's rmse: 0.376772\n",
            "[4200]\ttraining's l2: 0.132857\ttraining's rmse: 0.364495\tvalid_1's l2: 0.141328\tvalid_1's rmse: 0.375936\n",
            "[4400]\ttraining's l2: 0.132109\ttraining's rmse: 0.363468\tvalid_1's l2: 0.140845\tvalid_1's rmse: 0.375293\n",
            "[4600]\ttraining's l2: 0.131234\ttraining's rmse: 0.362262\tvalid_1's l2: 0.140224\tvalid_1's rmse: 0.374465\n",
            "[4800]\ttraining's l2: 0.130451\ttraining's rmse: 0.361181\tvalid_1's l2: 0.139705\tvalid_1's rmse: 0.373771\n",
            "[5000]\ttraining's l2: 0.129847\ttraining's rmse: 0.360343\tvalid_1's l2: 0.139384\tvalid_1's rmse: 0.373342\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[5000]\ttraining's l2: 0.129847\ttraining's rmse: 0.360343\tvalid_1's l2: 0.139384\tvalid_1's rmse: 0.373342\n",
            "1 err_lgm:  0.2981358399218599\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "[200]\ttraining's l2: 0.198717\ttraining's rmse: 0.445777\tvalid_1's l2: 0.200287\tvalid_1's rmse: 0.447535\n",
            "[400]\ttraining's l2: 0.179954\ttraining's rmse: 0.42421\tvalid_1's l2: 0.182201\tvalid_1's rmse: 0.426851\n",
            "[600]\ttraining's l2: 0.169574\ttraining's rmse: 0.411793\tvalid_1's l2: 0.17228\tvalid_1's rmse: 0.415067\n",
            "[800]\ttraining's l2: 0.162384\ttraining's rmse: 0.402969\tvalid_1's l2: 0.165493\tvalid_1's rmse: 0.406809\n",
            "[1000]\ttraining's l2: 0.157183\ttraining's rmse: 0.396463\tvalid_1's l2: 0.160598\tvalid_1's rmse: 0.400747\n",
            "[1200]\ttraining's l2: 0.153463\ttraining's rmse: 0.391743\tvalid_1's l2: 0.157412\tvalid_1's rmse: 0.396751\n",
            "[1400]\ttraining's l2: 0.15086\ttraining's rmse: 0.388407\tvalid_1's l2: 0.155252\tvalid_1's rmse: 0.39402\n",
            "[1600]\ttraining's l2: 0.148412\ttraining's rmse: 0.385242\tvalid_1's l2: 0.153295\tvalid_1's rmse: 0.39153\n",
            "[1800]\ttraining's l2: 0.14658\ttraining's rmse: 0.382858\tvalid_1's l2: 0.151859\tvalid_1's rmse: 0.389691\n",
            "[2000]\ttraining's l2: 0.144479\ttraining's rmse: 0.380104\tvalid_1's l2: 0.150143\tvalid_1's rmse: 0.387483\n",
            "[2200]\ttraining's l2: 0.14292\ttraining's rmse: 0.378047\tvalid_1's l2: 0.148885\tvalid_1's rmse: 0.385856\n",
            "[2400]\ttraining's l2: 0.14124\ttraining's rmse: 0.375819\tvalid_1's l2: 0.147519\tvalid_1's rmse: 0.384082\n",
            "[2600]\ttraining's l2: 0.139869\ttraining's rmse: 0.37399\tvalid_1's l2: 0.146509\tvalid_1's rmse: 0.382764\n",
            "[2800]\ttraining's l2: 0.138523\ttraining's rmse: 0.372187\tvalid_1's l2: 0.145573\tvalid_1's rmse: 0.381541\n",
            "[3000]\ttraining's l2: 0.137198\ttraining's rmse: 0.370402\tvalid_1's l2: 0.14475\tvalid_1's rmse: 0.38046\n",
            "[3200]\ttraining's l2: 0.1362\ttraining's rmse: 0.369053\tvalid_1's l2: 0.144125\tvalid_1's rmse: 0.379638\n",
            "[3400]\ttraining's l2: 0.134972\ttraining's rmse: 0.367386\tvalid_1's l2: 0.143266\tvalid_1's rmse: 0.378505\n",
            "[3600]\ttraining's l2: 0.133988\ttraining's rmse: 0.366043\tvalid_1's l2: 0.142706\tvalid_1's rmse: 0.377764\n",
            "[3800]\ttraining's l2: 0.133275\ttraining's rmse: 0.365069\tvalid_1's l2: 0.142291\tvalid_1's rmse: 0.377215\n",
            "[4000]\ttraining's l2: 0.132476\ttraining's rmse: 0.363973\tvalid_1's l2: 0.141788\tvalid_1's rmse: 0.376547\n",
            "[4200]\ttraining's l2: 0.131549\ttraining's rmse: 0.362697\tvalid_1's l2: 0.141224\tvalid_1's rmse: 0.375798\n",
            "[4400]\ttraining's l2: 0.130975\ttraining's rmse: 0.361905\tvalid_1's l2: 0.140894\tvalid_1's rmse: 0.375358\n",
            "[4600]\ttraining's l2: 0.130294\ttraining's rmse: 0.360963\tvalid_1's l2: 0.140525\tvalid_1's rmse: 0.374867\n",
            "[4800]\ttraining's l2: 0.129668\ttraining's rmse: 0.360095\tvalid_1's l2: 0.140172\tvalid_1's rmse: 0.374395\n",
            "[5000]\ttraining's l2: 0.129065\ttraining's rmse: 0.359256\tvalid_1's l2: 0.139752\tvalid_1's rmse: 0.373835\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[5000]\ttraining's l2: 0.129065\ttraining's rmse: 0.359256\tvalid_1's l2: 0.139752\tvalid_1's rmse: 0.373835\n",
            "2 err_lgm:  0.2998778503220301\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "[200]\ttraining's l2: 0.197648\ttraining's rmse: 0.444576\tvalid_1's l2: 0.207094\tvalid_1's rmse: 0.455076\n",
            "[400]\ttraining's l2: 0.178082\ttraining's rmse: 0.421997\tvalid_1's l2: 0.188175\tvalid_1's rmse: 0.433792\n",
            "[600]\ttraining's l2: 0.168458\ttraining's rmse: 0.410436\tvalid_1's l2: 0.178723\tvalid_1's rmse: 0.422756\n",
            "[800]\ttraining's l2: 0.161347\ttraining's rmse: 0.40168\tvalid_1's l2: 0.17223\tvalid_1's rmse: 0.415006\n",
            "[1000]\ttraining's l2: 0.156769\ttraining's rmse: 0.395941\tvalid_1's l2: 0.167869\tvalid_1's rmse: 0.409718\n",
            "[1200]\ttraining's l2: 0.153208\ttraining's rmse: 0.391418\tvalid_1's l2: 0.164672\tvalid_1's rmse: 0.405798\n",
            "[1400]\ttraining's l2: 0.150687\ttraining's rmse: 0.388185\tvalid_1's l2: 0.16246\tvalid_1's rmse: 0.403064\n",
            "[1600]\ttraining's l2: 0.148408\ttraining's rmse: 0.385238\tvalid_1's l2: 0.160409\tvalid_1's rmse: 0.400511\n",
            "[1800]\ttraining's l2: 0.146164\ttraining's rmse: 0.382315\tvalid_1's l2: 0.158523\tvalid_1's rmse: 0.398149\n",
            "[2000]\ttraining's l2: 0.144484\ttraining's rmse: 0.38011\tvalid_1's l2: 0.157072\tvalid_1's rmse: 0.396323\n",
            "[2200]\ttraining's l2: 0.143021\ttraining's rmse: 0.378181\tvalid_1's l2: 0.155797\tvalid_1's rmse: 0.394711\n",
            "[2400]\ttraining's l2: 0.141477\ttraining's rmse: 0.376134\tvalid_1's l2: 0.154439\tvalid_1's rmse: 0.392987\n",
            "[2600]\ttraining's l2: 0.139698\ttraining's rmse: 0.373762\tvalid_1's l2: 0.152981\tvalid_1's rmse: 0.391128\n",
            "[2800]\ttraining's l2: 0.138393\ttraining's rmse: 0.372012\tvalid_1's l2: 0.152034\tvalid_1's rmse: 0.389915\n",
            "[3000]\ttraining's l2: 0.137181\ttraining's rmse: 0.370379\tvalid_1's l2: 0.151121\tvalid_1's rmse: 0.388743\n",
            "[3200]\ttraining's l2: 0.136088\ttraining's rmse: 0.3689\tvalid_1's l2: 0.150265\tvalid_1's rmse: 0.387641\n",
            "[3400]\ttraining's l2: 0.135096\ttraining's rmse: 0.367554\tvalid_1's l2: 0.149553\tvalid_1's rmse: 0.386721\n",
            "[3600]\ttraining's l2: 0.134007\ttraining's rmse: 0.36607\tvalid_1's l2: 0.148689\tvalid_1's rmse: 0.385602\n",
            "[3800]\ttraining's l2: 0.133059\ttraining's rmse: 0.364773\tvalid_1's l2: 0.148014\tvalid_1's rmse: 0.384726\n",
            "[4000]\ttraining's l2: 0.132159\ttraining's rmse: 0.363537\tvalid_1's l2: 0.14736\tvalid_1's rmse: 0.383875\n",
            "[4200]\ttraining's l2: 0.1313\ttraining's rmse: 0.362354\tvalid_1's l2: 0.146679\tvalid_1's rmse: 0.382987\n",
            "[4400]\ttraining's l2: 0.130771\ttraining's rmse: 0.361623\tvalid_1's l2: 0.146328\tvalid_1's rmse: 0.382529\n",
            "[4600]\ttraining's l2: 0.130155\ttraining's rmse: 0.36077\tvalid_1's l2: 0.145957\tvalid_1's rmse: 0.382043\n",
            "[4800]\ttraining's l2: 0.129427\ttraining's rmse: 0.359759\tvalid_1's l2: 0.145439\tvalid_1's rmse: 0.381364\n",
            "[5000]\ttraining's l2: 0.128759\ttraining's rmse: 0.35883\tvalid_1's l2: 0.144975\tvalid_1's rmse: 0.380756\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[5000]\ttraining's l2: 0.128759\ttraining's rmse: 0.35883\tvalid_1's l2: 0.144975\tvalid_1's rmse: 0.380756\n",
            "3 err_lgm:  0.3074155061965792\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "[200]\ttraining's l2: 0.198118\ttraining's rmse: 0.445104\tvalid_1's l2: 0.195941\tvalid_1's rmse: 0.442653\n",
            "[400]\ttraining's l2: 0.180552\ttraining's rmse: 0.424914\tvalid_1's l2: 0.178743\tvalid_1's rmse: 0.42278\n",
            "[600]\ttraining's l2: 0.17077\ttraining's rmse: 0.413244\tvalid_1's l2: 0.169611\tvalid_1's rmse: 0.411838\n",
            "[800]\ttraining's l2: 0.163797\ttraining's rmse: 0.404718\tvalid_1's l2: 0.163527\tvalid_1's rmse: 0.404385\n",
            "[1000]\ttraining's l2: 0.158563\ttraining's rmse: 0.3982\tvalid_1's l2: 0.158976\tvalid_1's rmse: 0.398718\n",
            "[1200]\ttraining's l2: 0.154408\ttraining's rmse: 0.392948\tvalid_1's l2: 0.155317\tvalid_1's rmse: 0.394103\n",
            "[1400]\ttraining's l2: 0.152168\ttraining's rmse: 0.390088\tvalid_1's l2: 0.153598\tvalid_1's rmse: 0.391916\n",
            "[1600]\ttraining's l2: 0.14992\ttraining's rmse: 0.387196\tvalid_1's l2: 0.151697\tvalid_1's rmse: 0.389483\n",
            "[1800]\ttraining's l2: 0.147862\ttraining's rmse: 0.384528\tvalid_1's l2: 0.149972\tvalid_1's rmse: 0.387262\n",
            "[2000]\ttraining's l2: 0.145859\ttraining's rmse: 0.381915\tvalid_1's l2: 0.148225\tvalid_1's rmse: 0.385\n",
            "[2200]\ttraining's l2: 0.144013\ttraining's rmse: 0.379491\tvalid_1's l2: 0.146786\tvalid_1's rmse: 0.383126\n",
            "[2400]\ttraining's l2: 0.142452\ttraining's rmse: 0.377428\tvalid_1's l2: 0.145574\tvalid_1's rmse: 0.381542\n",
            "[2600]\ttraining's l2: 0.140568\ttraining's rmse: 0.374923\tvalid_1's l2: 0.143869\tvalid_1's rmse: 0.379301\n",
            "[2800]\ttraining's l2: 0.139097\ttraining's rmse: 0.372957\tvalid_1's l2: 0.142509\tvalid_1's rmse: 0.377503\n",
            "[3000]\ttraining's l2: 0.137798\ttraining's rmse: 0.371212\tvalid_1's l2: 0.141512\tvalid_1's rmse: 0.37618\n",
            "[3200]\ttraining's l2: 0.13685\ttraining's rmse: 0.369932\tvalid_1's l2: 0.14088\tvalid_1's rmse: 0.37534\n",
            "[3400]\ttraining's l2: 0.135814\ttraining's rmse: 0.36853\tvalid_1's l2: 0.140222\tvalid_1's rmse: 0.374462\n",
            "[3600]\ttraining's l2: 0.134932\ttraining's rmse: 0.367331\tvalid_1's l2: 0.139675\tvalid_1's rmse: 0.373731\n",
            "[4200]\ttraining's l2: 0.132514\ttraining's rmse: 0.364025\tvalid_1's l2: 0.138045\tvalid_1's rmse: 0.371544\n",
            "[4400]\ttraining's l2: 0.131748\ttraining's rmse: 0.362971\tvalid_1's l2: 0.137517\tvalid_1's rmse: 0.370833\n",
            "[4600]\ttraining's l2: 0.131059\ttraining's rmse: 0.362021\tvalid_1's l2: 0.137081\tvalid_1's rmse: 0.370245\n",
            "[4800]\ttraining's l2: 0.130491\ttraining's rmse: 0.361236\tvalid_1's l2: 0.136739\tvalid_1's rmse: 0.369783\n",
            "[5000]\ttraining's l2: 0.129822\ttraining's rmse: 0.360308\tvalid_1's l2: 0.136336\tvalid_1's rmse: 0.369237\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[5000]\ttraining's l2: 0.129822\ttraining's rmse: 0.360308\tvalid_1's l2: 0.136336\tvalid_1's rmse: 0.369237\n",
            "4 err_lgm:  0.2959457727767939\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "[200]\ttraining's l2: 0.198574\ttraining's rmse: 0.445616\tvalid_1's l2: 0.194617\tvalid_1's rmse: 0.441154\n",
            "[400]\ttraining's l2: 0.181237\ttraining's rmse: 0.425719\tvalid_1's l2: 0.178118\tvalid_1's rmse: 0.42204\n",
            "[600]\ttraining's l2: 0.170645\ttraining's rmse: 0.413092\tvalid_1's l2: 0.16805\tvalid_1's rmse: 0.409939\n",
            "[800]\ttraining's l2: 0.163102\ttraining's rmse: 0.403859\tvalid_1's l2: 0.160639\tvalid_1's rmse: 0.400798\n",
            "[1000]\ttraining's l2: 0.158377\ttraining's rmse: 0.397966\tvalid_1's l2: 0.156261\tvalid_1's rmse: 0.395299\n",
            "[1200]\ttraining's l2: 0.154968\ttraining's rmse: 0.39366\tvalid_1's l2: 0.153339\tvalid_1's rmse: 0.391585\n",
            "[1400]\ttraining's l2: 0.152511\ttraining's rmse: 0.390527\tvalid_1's l2: 0.151191\tvalid_1's rmse: 0.388833\n",
            "[1600]\ttraining's l2: 0.14988\ttraining's rmse: 0.387143\tvalid_1's l2: 0.148988\tvalid_1's rmse: 0.38599\n",
            "[1800]\ttraining's l2: 0.14794\ttraining's rmse: 0.384629\tvalid_1's l2: 0.147354\tvalid_1's rmse: 0.383867\n",
            "[2000]\ttraining's l2: 0.145938\ttraining's rmse: 0.382018\tvalid_1's l2: 0.145749\tvalid_1's rmse: 0.381771\n",
            "[2200]\ttraining's l2: 0.144101\ttraining's rmse: 0.379606\tvalid_1's l2: 0.144349\tvalid_1's rmse: 0.379933\n",
            "[2400]\ttraining's l2: 0.142392\ttraining's rmse: 0.377348\tvalid_1's l2: 0.14312\tvalid_1's rmse: 0.378312\n",
            "[2600]\ttraining's l2: 0.140911\ttraining's rmse: 0.375381\tvalid_1's l2: 0.142044\tvalid_1's rmse: 0.376888\n",
            "[3000]\ttraining's l2: 0.138226\ttraining's rmse: 0.371787\tvalid_1's l2: 0.139979\tvalid_1's rmse: 0.374137\n",
            "[3200]\ttraining's l2: 0.13699\ttraining's rmse: 0.370122\tvalid_1's l2: 0.139073\tvalid_1's rmse: 0.372925\n",
            "[3400]\ttraining's l2: 0.135761\ttraining's rmse: 0.368458\tvalid_1's l2: 0.138171\tvalid_1's rmse: 0.371714\n",
            "[3600]\ttraining's l2: 0.134642\ttraining's rmse: 0.366936\tvalid_1's l2: 0.137466\tvalid_1's rmse: 0.370764\n",
            "[3800]\ttraining's l2: 0.133832\ttraining's rmse: 0.36583\tvalid_1's l2: 0.137004\tvalid_1's rmse: 0.37014\n",
            "[4000]\ttraining's l2: 0.133043\ttraining's rmse: 0.364751\tvalid_1's l2: 0.136479\tvalid_1's rmse: 0.369431\n",
            "[4200]\ttraining's l2: 0.132079\ttraining's rmse: 0.363427\tvalid_1's l2: 0.135861\tvalid_1's rmse: 0.368593\n",
            "[4400]\ttraining's l2: 0.131478\ttraining's rmse: 0.362598\tvalid_1's l2: 0.135534\tvalid_1's rmse: 0.368149\n",
            "[4600]\ttraining's l2: 0.13072\ttraining's rmse: 0.361552\tvalid_1's l2: 0.135028\tvalid_1's rmse: 0.367462\n",
            "[4800]\ttraining's l2: 0.129966\ttraining's rmse: 0.360509\tvalid_1's l2: 0.134608\tvalid_1's rmse: 0.366889\n",
            "[5000]\ttraining's l2: 0.129365\ttraining's rmse: 0.359673\tvalid_1's l2: 0.134317\tvalid_1's rmse: 0.366493\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[5000]\ttraining's l2: 0.129365\ttraining's rmse: 0.359673\tvalid_1's l2: 0.134317\tvalid_1's rmse: 0.366493\n",
            "5 err_lgm:  0.2926799840115141\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "[200]\ttraining's l2: 0.196478\ttraining's rmse: 0.443258\tvalid_1's l2: 0.201649\tvalid_1's rmse: 0.449053\n",
            "[400]\ttraining's l2: 0.177353\ttraining's rmse: 0.421133\tvalid_1's l2: 0.182743\tvalid_1's rmse: 0.427484\n",
            "[600]\ttraining's l2: 0.167462\ttraining's rmse: 0.409221\tvalid_1's l2: 0.1729\tvalid_1's rmse: 0.415812\n",
            "[800]\ttraining's l2: 0.159734\ttraining's rmse: 0.399667\tvalid_1's l2: 0.165489\tvalid_1's rmse: 0.406804\n",
            "[1000]\ttraining's l2: 0.154701\ttraining's rmse: 0.39332\tvalid_1's l2: 0.16076\tvalid_1's rmse: 0.400949\n",
            "[1200]\ttraining's l2: 0.1509\ttraining's rmse: 0.388458\tvalid_1's l2: 0.157327\tvalid_1's rmse: 0.396644\n",
            "[1400]\ttraining's l2: 0.148411\ttraining's rmse: 0.385241\tvalid_1's l2: 0.155258\tvalid_1's rmse: 0.394028\n",
            "[1600]\ttraining's l2: 0.146004\ttraining's rmse: 0.382105\tvalid_1's l2: 0.153284\tvalid_1's rmse: 0.391515\n",
            "[1800]\ttraining's l2: 0.143758\ttraining's rmse: 0.379154\tvalid_1's l2: 0.151554\tvalid_1's rmse: 0.3893\n",
            "[2000]\ttraining's l2: 0.141807\ttraining's rmse: 0.376572\tvalid_1's l2: 0.150014\tvalid_1's rmse: 0.387317\n",
            "[2200]\ttraining's l2: 0.140111\ttraining's rmse: 0.374314\tvalid_1's l2: 0.148658\tvalid_1's rmse: 0.385562\n",
            "[2400]\ttraining's l2: 0.138371\ttraining's rmse: 0.371982\tvalid_1's l2: 0.147206\tvalid_1's rmse: 0.383674\n",
            "[2600]\ttraining's l2: 0.136941\ttraining's rmse: 0.370055\tvalid_1's l2: 0.146084\tvalid_1's rmse: 0.38221\n",
            "[2800]\ttraining's l2: 0.135633\ttraining's rmse: 0.368284\tvalid_1's l2: 0.144976\tvalid_1's rmse: 0.380758\n",
            "[3000]\ttraining's l2: 0.134356\ttraining's rmse: 0.366546\tvalid_1's l2: 0.143966\tvalid_1's rmse: 0.379429\n",
            "[3200]\ttraining's l2: 0.13324\ttraining's rmse: 0.36502\tvalid_1's l2: 0.143233\tvalid_1's rmse: 0.378461\n",
            "[3400]\ttraining's l2: 0.132228\ttraining's rmse: 0.363631\tvalid_1's l2: 0.142569\tvalid_1's rmse: 0.377583\n",
            "[3600]\ttraining's l2: 0.131426\ttraining's rmse: 0.362527\tvalid_1's l2: 0.141976\tvalid_1's rmse: 0.376797\n",
            "[3800]\ttraining's l2: 0.130677\ttraining's rmse: 0.361493\tvalid_1's l2: 0.141534\tvalid_1's rmse: 0.37621\n",
            "[4000]\ttraining's l2: 0.129876\ttraining's rmse: 0.360383\tvalid_1's l2: 0.141035\tvalid_1's rmse: 0.375547\n",
            "[4200]\ttraining's l2: 0.129021\ttraining's rmse: 0.359195\tvalid_1's l2: 0.140451\tvalid_1's rmse: 0.374768\n",
            "[4400]\ttraining's l2: 0.128314\ttraining's rmse: 0.35821\tvalid_1's l2: 0.140024\tvalid_1's rmse: 0.374198\n",
            "[4600]\ttraining's l2: 0.127538\ttraining's rmse: 0.357125\tvalid_1's l2: 0.139546\tvalid_1's rmse: 0.373559\n",
            "[4800]\ttraining's l2: 0.126862\ttraining's rmse: 0.356177\tvalid_1's l2: 0.139087\tvalid_1's rmse: 0.372944\n",
            "[5000]\ttraining's l2: 0.126183\ttraining's rmse: 0.355222\tvalid_1's l2: 0.138645\tvalid_1's rmse: 0.37235\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[5000]\ttraining's l2: 0.126183\ttraining's rmse: 0.355222\tvalid_1's l2: 0.138645\tvalid_1's rmse: 0.37235\n",
            "6 err_lgm:  0.298231809302046\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "[200]\ttraining's l2: 0.196704\ttraining's rmse: 0.443513\tvalid_1's l2: 0.196689\tvalid_1's rmse: 0.443496\n",
            "[400]\ttraining's l2: 0.177693\ttraining's rmse: 0.421536\tvalid_1's l2: 0.178454\tvalid_1's rmse: 0.422439\n",
            "[600]\ttraining's l2: 0.166426\ttraining's rmse: 0.407953\tvalid_1's l2: 0.167886\tvalid_1's rmse: 0.409739\n",
            "[800]\ttraining's l2: 0.159545\ttraining's rmse: 0.399431\tvalid_1's l2: 0.161419\tvalid_1's rmse: 0.40177\n",
            "[1000]\ttraining's l2: 0.154394\ttraining's rmse: 0.39293\tvalid_1's l2: 0.156647\tvalid_1's rmse: 0.395786\n",
            "[1200]\ttraining's l2: 0.15046\ttraining's rmse: 0.387892\tvalid_1's l2: 0.153096\tvalid_1's rmse: 0.391275\n",
            "[1400]\ttraining's l2: 0.148141\ttraining's rmse: 0.38489\tvalid_1's l2: 0.151154\tvalid_1's rmse: 0.388785\n",
            "[1600]\ttraining's l2: 0.14585\ttraining's rmse: 0.381903\tvalid_1's l2: 0.14917\tvalid_1's rmse: 0.386226\n",
            "[1800]\ttraining's l2: 0.144078\ttraining's rmse: 0.379576\tvalid_1's l2: 0.147723\tvalid_1's rmse: 0.384348\n",
            "[2000]\ttraining's l2: 0.142258\ttraining's rmse: 0.377172\tvalid_1's l2: 0.14623\tvalid_1's rmse: 0.382401\n",
            "[2200]\ttraining's l2: 0.14098\ttraining's rmse: 0.375474\tvalid_1's l2: 0.145255\tvalid_1's rmse: 0.381124\n",
            "[2400]\ttraining's l2: 0.139226\ttraining's rmse: 0.37313\tvalid_1's l2: 0.143938\tvalid_1's rmse: 0.379391\n",
            "[2600]\ttraining's l2: 0.137691\ttraining's rmse: 0.371068\tvalid_1's l2: 0.142758\tvalid_1's rmse: 0.377833\n",
            "[2800]\ttraining's l2: 0.136088\ttraining's rmse: 0.368901\tvalid_1's l2: 0.14152\tvalid_1's rmse: 0.376191\n",
            "[3000]\ttraining's l2: 0.134936\ttraining's rmse: 0.367337\tvalid_1's l2: 0.140616\tvalid_1's rmse: 0.374988\n",
            "[3200]\ttraining's l2: 0.133847\ttraining's rmse: 0.365851\tvalid_1's l2: 0.139876\tvalid_1's rmse: 0.374\n",
            "[3400]\ttraining's l2: 0.132685\ttraining's rmse: 0.364259\tvalid_1's l2: 0.139041\tvalid_1's rmse: 0.372882\n",
            "[3600]\ttraining's l2: 0.131601\ttraining's rmse: 0.362768\tvalid_1's l2: 0.1383\tvalid_1's rmse: 0.371887\n",
            "[3800]\ttraining's l2: 0.130756\ttraining's rmse: 0.361602\tvalid_1's l2: 0.137704\tvalid_1's rmse: 0.371085\n",
            "[4000]\ttraining's l2: 0.12987\ttraining's rmse: 0.360375\tvalid_1's l2: 0.13706\tvalid_1's rmse: 0.370215\n",
            "[4200]\ttraining's l2: 0.129101\ttraining's rmse: 0.359306\tvalid_1's l2: 0.136476\tvalid_1's rmse: 0.369426\n",
            "[4400]\ttraining's l2: 0.1284\ttraining's rmse: 0.358329\tvalid_1's l2: 0.136008\tvalid_1's rmse: 0.368792\n",
            "[4600]\ttraining's l2: 0.127598\ttraining's rmse: 0.357209\tvalid_1's l2: 0.135475\tvalid_1's rmse: 0.368069\n",
            "[4800]\ttraining's l2: 0.126754\ttraining's rmse: 0.356026\tvalid_1's l2: 0.1349\tvalid_1's rmse: 0.367288\n",
            "[5000]\ttraining's l2: 0.12616\ttraining's rmse: 0.35519\tvalid_1's l2: 0.134579\tvalid_1's rmse: 0.36685\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[5000]\ttraining's l2: 0.12616\ttraining's rmse: 0.35519\tvalid_1's l2: 0.134579\tvalid_1's rmse: 0.36685\n",
            "7 err_lgm:  0.2959896939217986\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "[200]\ttraining's l2: 0.196752\ttraining's rmse: 0.443567\tvalid_1's l2: 0.201269\tvalid_1's rmse: 0.448631\n",
            "[400]\ttraining's l2: 0.178119\ttraining's rmse: 0.422041\tvalid_1's l2: 0.183732\tvalid_1's rmse: 0.428639\n",
            "[600]\ttraining's l2: 0.166558\ttraining's rmse: 0.408116\tvalid_1's l2: 0.173167\tvalid_1's rmse: 0.416133\n",
            "[800]\ttraining's l2: 0.160131\ttraining's rmse: 0.400163\tvalid_1's l2: 0.167579\tvalid_1's rmse: 0.409364\n",
            "[1000]\ttraining's l2: 0.155404\ttraining's rmse: 0.394213\tvalid_1's l2: 0.163505\tvalid_1's rmse: 0.404357\n",
            "[1200]\ttraining's l2: 0.151467\ttraining's rmse: 0.389188\tvalid_1's l2: 0.160127\tvalid_1's rmse: 0.400159\n",
            "[1400]\ttraining's l2: 0.148858\ttraining's rmse: 0.385821\tvalid_1's l2: 0.158012\tvalid_1's rmse: 0.397508\n",
            "[1600]\ttraining's l2: 0.146538\ttraining's rmse: 0.382803\tvalid_1's l2: 0.156067\tvalid_1's rmse: 0.395053\n",
            "[1800]\ttraining's l2: 0.144253\ttraining's rmse: 0.379807\tvalid_1's l2: 0.154149\tvalid_1's rmse: 0.392618\n",
            "[2000]\ttraining's l2: 0.142505\ttraining's rmse: 0.377498\tvalid_1's l2: 0.152781\tvalid_1's rmse: 0.390873\n",
            "[2200]\ttraining's l2: 0.141016\ttraining's rmse: 0.375521\tvalid_1's l2: 0.151664\tvalid_1's rmse: 0.389441\n",
            "[2400]\ttraining's l2: 0.139424\ttraining's rmse: 0.373396\tvalid_1's l2: 0.150424\tvalid_1's rmse: 0.387845\n",
            "[2600]\ttraining's l2: 0.137974\ttraining's rmse: 0.371448\tvalid_1's l2: 0.149185\tvalid_1's rmse: 0.386245\n",
            "[2800]\ttraining's l2: 0.136744\ttraining's rmse: 0.369789\tvalid_1's l2: 0.148162\tvalid_1's rmse: 0.384918\n",
            "[3000]\ttraining's l2: 0.135668\ttraining's rmse: 0.368332\tvalid_1's l2: 0.14731\tvalid_1's rmse: 0.38381\n",
            "[3200]\ttraining's l2: 0.134673\ttraining's rmse: 0.366979\tvalid_1's l2: 0.146565\tvalid_1's rmse: 0.382839\n",
            "[3400]\ttraining's l2: 0.133508\ttraining's rmse: 0.365387\tvalid_1's l2: 0.145618\tvalid_1's rmse: 0.381599\n",
            "[3600]\ttraining's l2: 0.13257\ttraining's rmse: 0.364101\tvalid_1's l2: 0.144919\tvalid_1's rmse: 0.380683\n",
            "[3800]\ttraining's l2: 0.131754\ttraining's rmse: 0.362979\tvalid_1's l2: 0.144342\tvalid_1's rmse: 0.379923\n",
            "[4000]\ttraining's l2: 0.130774\ttraining's rmse: 0.361627\tvalid_1's l2: 0.143693\tvalid_1's rmse: 0.379069\n",
            "[4200]\ttraining's l2: 0.129919\ttraining's rmse: 0.360442\tvalid_1's l2: 0.143048\tvalid_1's rmse: 0.378217\n",
            "[4400]\ttraining's l2: 0.129253\ttraining's rmse: 0.359517\tvalid_1's l2: 0.1426\tvalid_1's rmse: 0.377624\n",
            "[4600]\ttraining's l2: 0.128628\ttraining's rmse: 0.358648\tvalid_1's l2: 0.142152\tvalid_1's rmse: 0.37703\n",
            "[4800]\ttraining's l2: 0.127909\ttraining's rmse: 0.357644\tvalid_1's l2: 0.141624\tvalid_1's rmse: 0.376329\n",
            "[5000]\ttraining's l2: 0.127267\ttraining's rmse: 0.356745\tvalid_1's l2: 0.141147\tvalid_1's rmse: 0.375696\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[5000]\ttraining's l2: 0.127267\ttraining's rmse: 0.356745\tvalid_1's l2: 0.141147\tvalid_1's rmse: 0.375696\n",
            "8 err_lgm:  0.30233383812886044\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "[200]\ttraining's l2: 0.19692\ttraining's rmse: 0.443757\tvalid_1's l2: 0.195612\tvalid_1's rmse: 0.442281\n",
            "[400]\ttraining's l2: 0.178958\ttraining's rmse: 0.423035\tvalid_1's l2: 0.178685\tvalid_1's rmse: 0.422712\n",
            "[600]\ttraining's l2: 0.168542\ttraining's rmse: 0.410539\tvalid_1's l2: 0.16909\tvalid_1's rmse: 0.411206\n",
            "[800]\ttraining's l2: 0.161254\ttraining's rmse: 0.401564\tvalid_1's l2: 0.162502\tvalid_1's rmse: 0.403116\n",
            "[1000]\ttraining's l2: 0.156251\ttraining's rmse: 0.395285\tvalid_1's l2: 0.158058\tvalid_1's rmse: 0.397565\n",
            "[1200]\ttraining's l2: 0.152809\ttraining's rmse: 0.390909\tvalid_1's l2: 0.155143\tvalid_1's rmse: 0.393882\n",
            "[1400]\ttraining's l2: 0.150589\ttraining's rmse: 0.388057\tvalid_1's l2: 0.153265\tvalid_1's rmse: 0.391491\n",
            "[1600]\ttraining's l2: 0.147676\ttraining's rmse: 0.384287\tvalid_1's l2: 0.15079\tvalid_1's rmse: 0.388317\n",
            "[1800]\ttraining's l2: 0.145574\ttraining's rmse: 0.381541\tvalid_1's l2: 0.149138\tvalid_1's rmse: 0.386183\n",
            "[2000]\ttraining's l2: 0.143952\ttraining's rmse: 0.379409\tvalid_1's l2: 0.147845\tvalid_1's rmse: 0.384506\n",
            "[2200]\ttraining's l2: 0.142372\ttraining's rmse: 0.377322\tvalid_1's l2: 0.146683\tvalid_1's rmse: 0.382992\n",
            "[2400]\ttraining's l2: 0.140605\ttraining's rmse: 0.374974\tvalid_1's l2: 0.145318\tvalid_1's rmse: 0.381206\n",
            "[2600]\ttraining's l2: 0.139102\ttraining's rmse: 0.372964\tvalid_1's l2: 0.144277\tvalid_1's rmse: 0.379839\n",
            "[2800]\ttraining's l2: 0.137736\ttraining's rmse: 0.371128\tvalid_1's l2: 0.143277\tvalid_1's rmse: 0.378519\n",
            "[3000]\ttraining's l2: 0.136446\ttraining's rmse: 0.369386\tvalid_1's l2: 0.142346\tvalid_1's rmse: 0.377288\n",
            "[3200]\ttraining's l2: 0.135433\ttraining's rmse: 0.368013\tvalid_1's l2: 0.141625\tvalid_1's rmse: 0.376331\n",
            "[3400]\ttraining's l2: 0.134397\ttraining's rmse: 0.366603\tvalid_1's l2: 0.140893\tvalid_1's rmse: 0.375357\n",
            "[3600]\ttraining's l2: 0.133262\ttraining's rmse: 0.365051\tvalid_1's l2: 0.140076\tvalid_1's rmse: 0.374267\n",
            "[3800]\ttraining's l2: 0.132513\ttraining's rmse: 0.364024\tvalid_1's l2: 0.139588\tvalid_1's rmse: 0.373615\n",
            "[4000]\ttraining's l2: 0.131803\ttraining's rmse: 0.363047\tvalid_1's l2: 0.139048\tvalid_1's rmse: 0.372891\n",
            "[4200]\ttraining's l2: 0.131056\ttraining's rmse: 0.362017\tvalid_1's l2: 0.138549\tvalid_1's rmse: 0.372221\n",
            "[4400]\ttraining's l2: 0.130419\ttraining's rmse: 0.361135\tvalid_1's l2: 0.138141\tvalid_1's rmse: 0.371673\n",
            "[4600]\ttraining's l2: 0.129783\ttraining's rmse: 0.360254\tvalid_1's l2: 0.137751\tvalid_1's rmse: 0.371148\n",
            "[4800]\ttraining's l2: 0.12919\ttraining's rmse: 0.359431\tvalid_1's l2: 0.137376\tvalid_1's rmse: 0.370643\n",
            "[5000]\ttraining's l2: 0.128502\ttraining's rmse: 0.358471\tvalid_1's l2: 0.136877\tvalid_1's rmse: 0.369969\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[5000]\ttraining's l2: 0.128502\ttraining's rmse: 0.358471\tvalid_1's l2: 0.136877\tvalid_1's rmse: 0.369969\n",
            "9 err_lgm:  0.29618254565820684\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "[200]\ttraining's l2: 0.196225\ttraining's rmse: 0.442973\tvalid_1's l2: 0.198796\tvalid_1's rmse: 0.445866\n",
            "[400]\ttraining's l2: 0.177371\ttraining's rmse: 0.421155\tvalid_1's l2: 0.18035\tvalid_1's rmse: 0.424676\n",
            "[600]\ttraining's l2: 0.166664\ttraining's rmse: 0.408245\tvalid_1's l2: 0.17002\tvalid_1's rmse: 0.412335\n",
            "[800]\ttraining's l2: 0.159879\ttraining's rmse: 0.399849\tvalid_1's l2: 0.163984\tvalid_1's rmse: 0.404949\n",
            "[1000]\ttraining's l2: 0.154658\ttraining's rmse: 0.393266\tvalid_1's l2: 0.159279\tvalid_1's rmse: 0.399098\n",
            "[1200]\ttraining's l2: 0.15071\ttraining's rmse: 0.388213\tvalid_1's l2: 0.155801\tvalid_1's rmse: 0.394717\n",
            "[1400]\ttraining's l2: 0.148253\ttraining's rmse: 0.385036\tvalid_1's l2: 0.153666\tvalid_1's rmse: 0.392003\n",
            "[1600]\ttraining's l2: 0.145893\ttraining's rmse: 0.381959\tvalid_1's l2: 0.151641\tvalid_1's rmse: 0.389412\n",
            "[1800]\ttraining's l2: 0.143941\ttraining's rmse: 0.379396\tvalid_1's l2: 0.150079\tvalid_1's rmse: 0.387401\n",
            "[2000]\ttraining's l2: 0.142239\ttraining's rmse: 0.377146\tvalid_1's l2: 0.148739\tvalid_1's rmse: 0.385667\n",
            "[2200]\ttraining's l2: 0.140707\ttraining's rmse: 0.375109\tvalid_1's l2: 0.147513\tvalid_1's rmse: 0.384074\n",
            "[2400]\ttraining's l2: 0.138919\ttraining's rmse: 0.372719\tvalid_1's l2: 0.146062\tvalid_1's rmse: 0.38218\n",
            "[2600]\ttraining's l2: 0.137515\ttraining's rmse: 0.370831\tvalid_1's l2: 0.144914\tvalid_1's rmse: 0.380675\n",
            "[2800]\ttraining's l2: 0.136165\ttraining's rmse: 0.369005\tvalid_1's l2: 0.143838\tvalid_1's rmse: 0.37926\n",
            "[3000]\ttraining's l2: 0.13499\ttraining's rmse: 0.367409\tvalid_1's l2: 0.143098\tvalid_1's rmse: 0.378283\n",
            "[3200]\ttraining's l2: 0.133949\ttraining's rmse: 0.365991\tvalid_1's l2: 0.142381\tvalid_1's rmse: 0.377334\n",
            "[3400]\ttraining's l2: 0.133049\ttraining's rmse: 0.364759\tvalid_1's l2: 0.141726\tvalid_1's rmse: 0.376465\n",
            "[3600]\ttraining's l2: 0.132027\ttraining's rmse: 0.363355\tvalid_1's l2: 0.140982\tvalid_1's rmse: 0.375476\n",
            "[3800]\ttraining's l2: 0.131236\ttraining's rmse: 0.362265\tvalid_1's l2: 0.140382\tvalid_1's rmse: 0.374676\n",
            "[4000]\ttraining's l2: 0.130569\ttraining's rmse: 0.361343\tvalid_1's l2: 0.139985\tvalid_1's rmse: 0.374145\n",
            "[4200]\ttraining's l2: 0.129694\ttraining's rmse: 0.360131\tvalid_1's l2: 0.139297\tvalid_1's rmse: 0.373225\n",
            "[4400]\ttraining's l2: 0.129047\ttraining's rmse: 0.359231\tvalid_1's l2: 0.138871\tvalid_1's rmse: 0.372654\n",
            "[4600]\ttraining's l2: 0.12831\ttraining's rmse: 0.358204\tvalid_1's l2: 0.138354\tvalid_1's rmse: 0.37196\n",
            "[4800]\ttraining's l2: 0.127626\ttraining's rmse: 0.357248\tvalid_1's l2: 0.137938\tvalid_1's rmse: 0.3714\n",
            "[5000]\ttraining's l2: 0.127099\ttraining's rmse: 0.356509\tvalid_1's l2: 0.137643\tvalid_1's rmse: 0.371003\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[5000]\ttraining's l2: 0.127099\ttraining's rmse: 0.356509\tvalid_1's l2: 0.137643\tvalid_1's rmse: 0.371003\n",
            "10 err_lgm:  0.29713465487852103\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "[200]\ttraining's l2: 0.194887\ttraining's rmse: 0.44146\tvalid_1's l2: 0.192859\tvalid_1's rmse: 0.439157\n",
            "[400]\ttraining's l2: 0.175661\ttraining's rmse: 0.41912\tvalid_1's l2: 0.174189\tvalid_1's rmse: 0.41736\n",
            "[600]\ttraining's l2: 0.165073\ttraining's rmse: 0.406291\tvalid_1's l2: 0.164278\tvalid_1's rmse: 0.405312\n",
            "[800]\ttraining's l2: 0.15839\ttraining's rmse: 0.397982\tvalid_1's l2: 0.157959\tvalid_1's rmse: 0.397441\n",
            "[1000]\ttraining's l2: 0.153391\ttraining's rmse: 0.391651\tvalid_1's l2: 0.153426\tvalid_1's rmse: 0.391696\n",
            "[1200]\ttraining's l2: 0.149392\ttraining's rmse: 0.386513\tvalid_1's l2: 0.149828\tvalid_1's rmse: 0.387077\n",
            "[1400]\ttraining's l2: 0.147088\ttraining's rmse: 0.383521\tvalid_1's l2: 0.147834\tvalid_1's rmse: 0.384492\n",
            "[1600]\ttraining's l2: 0.144685\ttraining's rmse: 0.380375\tvalid_1's l2: 0.145836\tvalid_1's rmse: 0.381884\n",
            "[1800]\ttraining's l2: 0.142756\ttraining's rmse: 0.377831\tvalid_1's l2: 0.144241\tvalid_1's rmse: 0.37979\n",
            "[2000]\ttraining's l2: 0.140992\ttraining's rmse: 0.375489\tvalid_1's l2: 0.142857\tvalid_1's rmse: 0.377964\n",
            "[2200]\ttraining's l2: 0.139356\ttraining's rmse: 0.373304\tvalid_1's l2: 0.141654\tvalid_1's rmse: 0.376369\n",
            "[2400]\ttraining's l2: 0.137749\ttraining's rmse: 0.371146\tvalid_1's l2: 0.140409\tvalid_1's rmse: 0.374713\n",
            "[2600]\ttraining's l2: 0.136358\ttraining's rmse: 0.369267\tvalid_1's l2: 0.139398\tvalid_1's rmse: 0.373361\n",
            "[2800]\ttraining's l2: 0.13478\ttraining's rmse: 0.367125\tvalid_1's l2: 0.138225\tvalid_1's rmse: 0.371787\n",
            "[3000]\ttraining's l2: 0.133561\ttraining's rmse: 0.365461\tvalid_1's l2: 0.137357\tvalid_1's rmse: 0.370617\n",
            "[3200]\ttraining's l2: 0.132421\ttraining's rmse: 0.363896\tvalid_1's l2: 0.136553\tvalid_1's rmse: 0.369531\n",
            "[3400]\ttraining's l2: 0.131344\ttraining's rmse: 0.362415\tvalid_1's l2: 0.135791\tvalid_1's rmse: 0.368498\n",
            "[3600]\ttraining's l2: 0.130392\ttraining's rmse: 0.361099\tvalid_1's l2: 0.135187\tvalid_1's rmse: 0.367678\n",
            "[3800]\ttraining's l2: 0.12954\ttraining's rmse: 0.359917\tvalid_1's l2: 0.13465\tvalid_1's rmse: 0.366947\n",
            "[4000]\ttraining's l2: 0.128761\ttraining's rmse: 0.358832\tvalid_1's l2: 0.13416\tvalid_1's rmse: 0.366279\n",
            "[4200]\ttraining's l2: 0.127848\ttraining's rmse: 0.357559\tvalid_1's l2: 0.133467\tvalid_1's rmse: 0.365331\n",
            "[4400]\ttraining's l2: 0.12719\ttraining's rmse: 0.356637\tvalid_1's l2: 0.133023\tvalid_1's rmse: 0.364723\n",
            "[4600]\ttraining's l2: 0.126349\ttraining's rmse: 0.355456\tvalid_1's l2: 0.132646\tvalid_1's rmse: 0.364206\n",
            "[4800]\ttraining's l2: 0.125786\ttraining's rmse: 0.354663\tvalid_1's l2: 0.132309\tvalid_1's rmse: 0.363743\n",
            "[5000]\ttraining's l2: 0.125118\ttraining's rmse: 0.353721\tvalid_1's l2: 0.131873\tvalid_1's rmse: 0.363143\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[5000]\ttraining's l2: 0.125118\ttraining's rmse: 0.353721\tvalid_1's l2: 0.131873\tvalid_1's rmse: 0.363143\n",
            "11 err_lgm:  0.29113964766098044\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "[200]\ttraining's l2: 0.196964\ttraining's rmse: 0.443807\tvalid_1's l2: 0.20111\tvalid_1's rmse: 0.448453\n",
            "[400]\ttraining's l2: 0.179307\ttraining's rmse: 0.423447\tvalid_1's l2: 0.18417\tvalid_1's rmse: 0.42915\n",
            "[600]\ttraining's l2: 0.168426\ttraining's rmse: 0.410397\tvalid_1's l2: 0.173816\tvalid_1's rmse: 0.416912\n",
            "[800]\ttraining's l2: 0.161277\ttraining's rmse: 0.401593\tvalid_1's l2: 0.166931\tvalid_1's rmse: 0.408572\n",
            "[1000]\ttraining's l2: 0.156453\ttraining's rmse: 0.395541\tvalid_1's l2: 0.162444\tvalid_1's rmse: 0.403044\n",
            "[1200]\ttraining's l2: 0.1525\ttraining's rmse: 0.390512\tvalid_1's l2: 0.158867\tvalid_1's rmse: 0.398581\n",
            "[1400]\ttraining's l2: 0.149828\ttraining's rmse: 0.387076\tvalid_1's l2: 0.156644\tvalid_1's rmse: 0.395783\n",
            "[1600]\ttraining's l2: 0.147291\ttraining's rmse: 0.383785\tvalid_1's l2: 0.15462\tvalid_1's rmse: 0.393218\n",
            "[1800]\ttraining's l2: 0.14528\ttraining's rmse: 0.381157\tvalid_1's l2: 0.153042\tvalid_1's rmse: 0.391206\n",
            "[2000]\ttraining's l2: 0.14341\ttraining's rmse: 0.378695\tvalid_1's l2: 0.151442\tvalid_1's rmse: 0.389156\n",
            "[2200]\ttraining's l2: 0.14155\ttraining's rmse: 0.376231\tvalid_1's l2: 0.149864\tvalid_1's rmse: 0.387122\n",
            "[2400]\ttraining's l2: 0.139708\ttraining's rmse: 0.373775\tvalid_1's l2: 0.148348\tvalid_1's rmse: 0.385159\n",
            "[2600]\ttraining's l2: 0.138126\ttraining's rmse: 0.371653\tvalid_1's l2: 0.14712\tvalid_1's rmse: 0.383562\n",
            "[2800]\ttraining's l2: 0.136689\ttraining's rmse: 0.369714\tvalid_1's l2: 0.145967\tvalid_1's rmse: 0.382056\n",
            "[3000]\ttraining's l2: 0.135322\ttraining's rmse: 0.367861\tvalid_1's l2: 0.144923\tvalid_1's rmse: 0.380688\n",
            "[3200]\ttraining's l2: 0.13428\ttraining's rmse: 0.366442\tvalid_1's l2: 0.144081\tvalid_1's rmse: 0.37958\n",
            "[3400]\ttraining's l2: 0.133404\ttraining's rmse: 0.365246\tvalid_1's l2: 0.143514\tvalid_1's rmse: 0.378832\n",
            "[3600]\ttraining's l2: 0.132431\ttraining's rmse: 0.363911\tvalid_1's l2: 0.142852\tvalid_1's rmse: 0.377958\n",
            "[3800]\ttraining's l2: 0.131601\ttraining's rmse: 0.362768\tvalid_1's l2: 0.142351\tvalid_1's rmse: 0.377294\n",
            "[4000]\ttraining's l2: 0.13091\ttraining's rmse: 0.361816\tvalid_1's l2: 0.141953\tvalid_1's rmse: 0.376767\n",
            "[4200]\ttraining's l2: 0.129777\ttraining's rmse: 0.360245\tvalid_1's l2: 0.141194\tvalid_1's rmse: 0.375758\n",
            "[4400]\ttraining's l2: 0.129091\ttraining's rmse: 0.359292\tvalid_1's l2: 0.140826\tvalid_1's rmse: 0.375268\n",
            "[4600]\ttraining's l2: 0.128314\ttraining's rmse: 0.358209\tvalid_1's l2: 0.140224\tvalid_1's rmse: 0.374465\n",
            "[4800]\ttraining's l2: 0.127567\ttraining's rmse: 0.357165\tvalid_1's l2: 0.139674\tvalid_1's rmse: 0.37373\n",
            "[5000]\ttraining's l2: 0.126994\ttraining's rmse: 0.356362\tvalid_1's l2: 0.139262\tvalid_1's rmse: 0.373178\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[5000]\ttraining's l2: 0.126994\ttraining's rmse: 0.356362\tvalid_1's l2: 0.139262\tvalid_1's rmse: 0.373178\n",
            "12 err_lgm:  0.30053240420369115\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "[200]\ttraining's l2: 0.197212\ttraining's rmse: 0.444085\tvalid_1's l2: 0.201123\tvalid_1's rmse: 0.448468\n",
            "[400]\ttraining's l2: 0.177962\ttraining's rmse: 0.421855\tvalid_1's l2: 0.182707\tvalid_1's rmse: 0.427443\n",
            "[600]\ttraining's l2: 0.168005\ttraining's rmse: 0.409884\tvalid_1's l2: 0.173235\tvalid_1's rmse: 0.416216\n",
            "[800]\ttraining's l2: 0.160309\ttraining's rmse: 0.400387\tvalid_1's l2: 0.166173\tvalid_1's rmse: 0.407643\n",
            "[1000]\ttraining's l2: 0.155531\ttraining's rmse: 0.394374\tvalid_1's l2: 0.161667\tvalid_1's rmse: 0.402078\n",
            "[1200]\ttraining's l2: 0.151934\ttraining's rmse: 0.389788\tvalid_1's l2: 0.158625\tvalid_1's rmse: 0.398278\n",
            "[1400]\ttraining's l2: 0.149652\ttraining's rmse: 0.386849\tvalid_1's l2: 0.156763\tvalid_1's rmse: 0.395934\n",
            "[1600]\ttraining's l2: 0.1473\ttraining's rmse: 0.383797\tvalid_1's l2: 0.154823\tvalid_1's rmse: 0.393475\n",
            "[1800]\ttraining's l2: 0.145255\ttraining's rmse: 0.381124\tvalid_1's l2: 0.153223\tvalid_1's rmse: 0.391437\n",
            "[2000]\ttraining's l2: 0.143498\ttraining's rmse: 0.378812\tvalid_1's l2: 0.151904\tvalid_1's rmse: 0.389749\n",
            "[2200]\ttraining's l2: 0.141951\ttraining's rmse: 0.376764\tvalid_1's l2: 0.150696\tvalid_1's rmse: 0.388196\n",
            "[2400]\ttraining's l2: 0.140259\ttraining's rmse: 0.374512\tvalid_1's l2: 0.149404\tvalid_1's rmse: 0.386528\n",
            "[2600]\ttraining's l2: 0.138707\ttraining's rmse: 0.372433\tvalid_1's l2: 0.14827\tvalid_1's rmse: 0.385059\n",
            "[2800]\ttraining's l2: 0.137135\ttraining's rmse: 0.370317\tvalid_1's l2: 0.147081\tvalid_1's rmse: 0.383511\n",
            "[3000]\ttraining's l2: 0.135948\ttraining's rmse: 0.368711\tvalid_1's l2: 0.146128\tvalid_1's rmse: 0.382267\n",
            "[3200]\ttraining's l2: 0.134833\ttraining's rmse: 0.367197\tvalid_1's l2: 0.145376\tvalid_1's rmse: 0.381282\n",
            "[3400]\ttraining's l2: 0.133888\ttraining's rmse: 0.365906\tvalid_1's l2: 0.144693\tvalid_1's rmse: 0.380385\n",
            "[3600]\ttraining's l2: 0.132874\ttraining's rmse: 0.364519\tvalid_1's l2: 0.143967\tvalid_1's rmse: 0.37943\n",
            "[3800]\ttraining's l2: 0.131953\ttraining's rmse: 0.363254\tvalid_1's l2: 0.143302\tvalid_1's rmse: 0.378553\n",
            "[4000]\ttraining's l2: 0.131122\ttraining's rmse: 0.362108\tvalid_1's l2: 0.142801\tvalid_1's rmse: 0.37789\n",
            "[4200]\ttraining's l2: 0.129962\ttraining's rmse: 0.360502\tvalid_1's l2: 0.141895\tvalid_1's rmse: 0.376689\n",
            "[4400]\ttraining's l2: 0.129359\ttraining's rmse: 0.359666\tvalid_1's l2: 0.141503\tvalid_1's rmse: 0.376169\n",
            "[4600]\ttraining's l2: 0.128816\ttraining's rmse: 0.358909\tvalid_1's l2: 0.141187\tvalid_1's rmse: 0.375748\n",
            "[4800]\ttraining's l2: 0.128144\ttraining's rmse: 0.357972\tvalid_1's l2: 0.140775\tvalid_1's rmse: 0.3752\n",
            "[5000]\ttraining's l2: 0.127488\ttraining's rmse: 0.357055\tvalid_1's l2: 0.140347\tvalid_1's rmse: 0.374629\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[5000]\ttraining's l2: 0.127488\ttraining's rmse: 0.357055\tvalid_1's l2: 0.140347\tvalid_1's rmse: 0.374629\n",
            "13 err_lgm:  0.3015178124686879\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "[200]\ttraining's l2: 0.196637\ttraining's rmse: 0.443437\tvalid_1's l2: 0.197643\tvalid_1's rmse: 0.444571\n",
            "[400]\ttraining's l2: 0.178419\ttraining's rmse: 0.422396\tvalid_1's l2: 0.18043\tvalid_1's rmse: 0.424771\n",
            "[600]\ttraining's l2: 0.167564\ttraining's rmse: 0.409346\tvalid_1's l2: 0.170439\tvalid_1's rmse: 0.412842\n",
            "[800]\ttraining's l2: 0.160465\ttraining's rmse: 0.400581\tvalid_1's l2: 0.164022\tvalid_1's rmse: 0.404996\n",
            "[1000]\ttraining's l2: 0.155652\ttraining's rmse: 0.394528\tvalid_1's l2: 0.159772\tvalid_1's rmse: 0.399714\n",
            "[1200]\ttraining's l2: 0.151838\ttraining's rmse: 0.389663\tvalid_1's l2: 0.156644\tvalid_1's rmse: 0.395783\n",
            "[1400]\ttraining's l2: 0.149062\ttraining's rmse: 0.386086\tvalid_1's l2: 0.154259\tvalid_1's rmse: 0.392758\n",
            "[1600]\ttraining's l2: 0.146916\ttraining's rmse: 0.383296\tvalid_1's l2: 0.152536\tvalid_1's rmse: 0.390559\n",
            "[1800]\ttraining's l2: 0.14521\ttraining's rmse: 0.381064\tvalid_1's l2: 0.151304\tvalid_1's rmse: 0.388978\n",
            "[2000]\ttraining's l2: 0.143485\ttraining's rmse: 0.378795\tvalid_1's l2: 0.149926\tvalid_1's rmse: 0.387203\n",
            "[2200]\ttraining's l2: 0.141787\ttraining's rmse: 0.376546\tvalid_1's l2: 0.148606\tvalid_1's rmse: 0.385495\n",
            "[2400]\ttraining's l2: 0.140303\ttraining's rmse: 0.374571\tvalid_1's l2: 0.147533\tvalid_1's rmse: 0.3841\n",
            "[2600]\ttraining's l2: 0.13866\ttraining's rmse: 0.37237\tvalid_1's l2: 0.146308\tvalid_1's rmse: 0.382502\n",
            "[2800]\ttraining's l2: 0.137028\ttraining's rmse: 0.370173\tvalid_1's l2: 0.145142\tvalid_1's rmse: 0.380976\n",
            "[3000]\ttraining's l2: 0.135889\ttraining's rmse: 0.368631\tvalid_1's l2: 0.144239\tvalid_1's rmse: 0.379788\n",
            "[3200]\ttraining's l2: 0.134836\ttraining's rmse: 0.3672\tvalid_1's l2: 0.143537\tvalid_1's rmse: 0.378862\n",
            "[3400]\ttraining's l2: 0.133814\ttraining's rmse: 0.365805\tvalid_1's l2: 0.142825\tvalid_1's rmse: 0.377921\n",
            "[3600]\ttraining's l2: 0.132774\ttraining's rmse: 0.364381\tvalid_1's l2: 0.14208\tvalid_1's rmse: 0.376934\n",
            "[3800]\ttraining's l2: 0.131795\ttraining's rmse: 0.363036\tvalid_1's l2: 0.141366\tvalid_1's rmse: 0.375986\n",
            "[4000]\ttraining's l2: 0.130896\ttraining's rmse: 0.361795\tvalid_1's l2: 0.140784\tvalid_1's rmse: 0.375211\n",
            "[4200]\ttraining's l2: 0.129957\ttraining's rmse: 0.360496\tvalid_1's l2: 0.140131\tvalid_1's rmse: 0.37434\n",
            "[4400]\ttraining's l2: 0.129266\ttraining's rmse: 0.359537\tvalid_1's l2: 0.139733\tvalid_1's rmse: 0.373809\n",
            "[4600]\ttraining's l2: 0.128565\ttraining's rmse: 0.358559\tvalid_1's l2: 0.139389\tvalid_1's rmse: 0.373349\n",
            "[4800]\ttraining's l2: 0.127964\ttraining's rmse: 0.357721\tvalid_1's l2: 0.13897\tvalid_1's rmse: 0.372787\n",
            "[5000]\ttraining's l2: 0.127419\ttraining's rmse: 0.356958\tvalid_1's l2: 0.138624\tvalid_1's rmse: 0.372322\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[5000]\ttraining's l2: 0.127419\ttraining's rmse: 0.356958\tvalid_1's l2: 0.138624\tvalid_1's rmse: 0.372322\n",
            "14 err_lgm:  0.2978770552143093\n",
            "Training until validation scores don't improve for 200 rounds.\n",
            "[200]\ttraining's l2: 0.197336\ttraining's rmse: 0.444225\tvalid_1's l2: 0.192798\tvalid_1's rmse: 0.439088\n",
            "[400]\ttraining's l2: 0.178503\ttraining's rmse: 0.422496\tvalid_1's l2: 0.174837\tvalid_1's rmse: 0.418136\n",
            "[600]\ttraining's l2: 0.168595\ttraining's rmse: 0.410604\tvalid_1's l2: 0.165854\tvalid_1's rmse: 0.407252\n",
            "[800]\ttraining's l2: 0.161437\ttraining's rmse: 0.401792\tvalid_1's l2: 0.159696\tvalid_1's rmse: 0.39962\n",
            "[1000]\ttraining's l2: 0.156199\ttraining's rmse: 0.395221\tvalid_1's l2: 0.155417\tvalid_1's rmse: 0.39423\n",
            "[1200]\ttraining's l2: 0.152803\ttraining's rmse: 0.3909\tvalid_1's l2: 0.152752\tvalid_1's rmse: 0.390835\n",
            "[1400]\ttraining's l2: 0.150458\ttraining's rmse: 0.387889\tvalid_1's l2: 0.151137\tvalid_1's rmse: 0.388764\n",
            "[1600]\ttraining's l2: 0.147763\ttraining's rmse: 0.3844\tvalid_1's l2: 0.148987\tvalid_1's rmse: 0.385988\n",
            "[1800]\ttraining's l2: 0.145504\ttraining's rmse: 0.381449\tvalid_1's l2: 0.147294\tvalid_1's rmse: 0.38379\n",
            "[2000]\ttraining's l2: 0.143735\ttraining's rmse: 0.379124\tvalid_1's l2: 0.145967\tvalid_1's rmse: 0.382056\n",
            "[2200]\ttraining's l2: 0.142076\ttraining's rmse: 0.376929\tvalid_1's l2: 0.144773\tvalid_1's rmse: 0.38049\n",
            "[2400]\ttraining's l2: 0.140686\ttraining's rmse: 0.375082\tvalid_1's l2: 0.143745\tvalid_1's rmse: 0.379137\n",
            "[2600]\ttraining's l2: 0.13931\ttraining's rmse: 0.373243\tvalid_1's l2: 0.142933\tvalid_1's rmse: 0.378065\n",
            "[2800]\ttraining's l2: 0.137906\ttraining's rmse: 0.371357\tvalid_1's l2: 0.141947\tvalid_1's rmse: 0.376759\n",
            "[3000]\ttraining's l2: 0.136677\ttraining's rmse: 0.369698\tvalid_1's l2: 0.141114\tvalid_1's rmse: 0.375652\n",
            "[3200]\ttraining's l2: 0.135685\ttraining's rmse: 0.368355\tvalid_1's l2: 0.140642\tvalid_1's rmse: 0.375022\n",
            "[3400]\ttraining's l2: 0.134817\ttraining's rmse: 0.367175\tvalid_1's l2: 0.140077\tvalid_1's rmse: 0.374268\n",
            "[3600]\ttraining's l2: 0.133757\ttraining's rmse: 0.365727\tvalid_1's l2: 0.139362\tvalid_1's rmse: 0.373312\n",
            "[3800]\ttraining's l2: 0.132868\ttraining's rmse: 0.36451\tvalid_1's l2: 0.138855\tvalid_1's rmse: 0.372633\n",
            "[4000]\ttraining's l2: 0.132032\ttraining's rmse: 0.363362\tvalid_1's l2: 0.138238\tvalid_1's rmse: 0.371803\n",
            "[4200]\ttraining's l2: 0.131028\ttraining's rmse: 0.361978\tvalid_1's l2: 0.137568\tvalid_1's rmse: 0.370902\n",
            "[4400]\ttraining's l2: 0.130499\ttraining's rmse: 0.361246\tvalid_1's l2: 0.13724\tvalid_1's rmse: 0.370459\n",
            "[4600]\ttraining's l2: 0.129681\ttraining's rmse: 0.360113\tvalid_1's l2: 0.136816\tvalid_1's rmse: 0.369887\n",
            "[4800]\ttraining's l2: 0.128964\ttraining's rmse: 0.359116\tvalid_1's l2: 0.136395\tvalid_1's rmse: 0.369317\n",
            "[5000]\ttraining's l2: 0.128395\ttraining's rmse: 0.358323\tvalid_1's l2: 0.136074\tvalid_1's rmse: 0.368882\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[5000]\ttraining's l2: 0.128395\ttraining's rmse: 0.358323\tvalid_1's l2: 0.136074\tvalid_1's rmse: 0.368882\n",
            "15 err_lgm:  0.2958660850085085\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yilD4G9NikKK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "133745ef-fc84-4579-b14e-6885dc59913a"
      },
      "source": [
        "np.mean(err,0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2980573666449592"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lnI9F80lZUo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "2354269c-62f4-4740-993f-68553820c669"
      },
      "source": [
        "submission = pd.DataFrame()\n",
        "submission['UnitPrice'] = np.exp(np.mean(y_pred_tot_lgm, 0))\n",
        "submission.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>UnitPrice</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3.228187</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.211240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3.197397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>5.901172</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.685695</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   UnitPrice\n",
              "0   3.228187\n",
              "1   4.211240\n",
              "2   3.197397\n",
              "3   5.901172\n",
              "4   4.685695"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaFdeRP1mEFY"
      },
      "source": [
        "submission.to_excel('submission.xlsx', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
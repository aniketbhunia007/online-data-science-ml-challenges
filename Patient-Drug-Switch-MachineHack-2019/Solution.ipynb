{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/fitness/fitness_values_2.csv\n",
      "/kaggle/input/armanik-patient-drugswitch/Drug_Switch_Prediction_ParticipantsData/fitness_values.csv\n",
      "/kaggle/input/armanik-patient-drugswitch/Drug_Switch_Prediction_ParticipantsData/train_data.csv\n",
      "/kaggle/input/armanik-patient-drugswitch/Drug_Switch_Prediction_ParticipantsData/test_data.csv\n",
      "/kaggle/input/armanik-patient-drugswitch/Drug_Switch_Prediction_ParticipantsData/train_labels.csv\n",
      "/kaggle/input/armanik-patient-drugswitch/Drug_Switch_Prediction_ParticipantsData/Sample Submission.csv\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/armanik-patient-drugswitch/Drug_Switch_Prediction_ParticipantsData/train_data.csv')\n",
    "test = pd.read_csv('../input/armanik-patient-drugswitch/Drug_Switch_Prediction_ParticipantsData/test_data.csv')\n",
    "train_labels = pd.read_csv('../input/armanik-patient-drugswitch/Drug_Switch_Prediction_ParticipantsData/train_labels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_fitness = pd.read_csv(\"/kaggle/input/fitness/fitness_values_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_copy = train.copy()\n",
    "test_copy = test.copy()\n",
    "train_labels_copy = train_labels.copy()\n",
    "fitness_copy = all_fitness.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>event_name</th>\n",
       "      <th>event_time</th>\n",
       "      <th>specialty</th>\n",
       "      <th>plan_type</th>\n",
       "      <th>patient_payment</th>\n",
       "      <th>outcome_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>patient_1</td>\n",
       "      <td>event_1</td>\n",
       "      <td>47</td>\n",
       "      <td>spec_1</td>\n",
       "      <td>plan_1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>patient_4</td>\n",
       "      <td>event_1</td>\n",
       "      <td>727</td>\n",
       "      <td>spec_1</td>\n",
       "      <td>plan_2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>patient_6</td>\n",
       "      <td>event_1</td>\n",
       "      <td>738</td>\n",
       "      <td>spec_1</td>\n",
       "      <td>plan_1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>patient_7</td>\n",
       "      <td>event_1</td>\n",
       "      <td>923</td>\n",
       "      <td>spec_1</td>\n",
       "      <td>plan_1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>patient_9</td>\n",
       "      <td>event_1</td>\n",
       "      <td>49</td>\n",
       "      <td>spec_1</td>\n",
       "      <td>plan_1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  patient_id event_name  event_time specialty plan_type  patient_payment  \\\n",
       "0  patient_1    event_1          47    spec_1    plan_1              0.0   \n",
       "1  patient_4    event_1         727    spec_1    plan_2              0.0   \n",
       "2  patient_6    event_1         738    spec_1    plan_1              0.0   \n",
       "3  patient_7    event_1         923    spec_1    plan_1              0.0   \n",
       "4  patient_9    event_1          49    spec_1    plan_1              0.0   \n",
       "\n",
       "   outcome_flag  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.merge(train, train_labels, on='patient_id', how='left')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:7138: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort,\n"
     ]
    }
   ],
   "source": [
    "combine = train.append(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23831, 6)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combine['event_time'].fillna(-1, inplace=True)\n",
    "combine['patient_payment'].fillna(-1, inplace=True)\n",
    "grouping_pid = combine.groupby('patient_id')\n",
    "patient_ids = combine.drop_duplicates('patient_id')['patient_id'].tolist()\n",
    "\n",
    "event_name_list = []\n",
    "specialty_list = []\n",
    "plan_type_list = []\n",
    "event_time_list = []\n",
    "patient_payment_list = []\n",
    "outcome_flag_list = []\n",
    "\n",
    "# .drop_duplicates('event_name') .drop_duplicates('event_name') .drop_duplicates('specialty').drop_duplicates('plan_type')\n",
    "\n",
    "for patient_id in patient_ids:\n",
    "    event_name_list.append(grouping_pid.get_group(patient_id)['event_name'].tolist())\n",
    "    specialty_list.append(grouping_pid.get_group(patient_id)['specialty'].tolist())\n",
    "    plan_type_list.append(grouping_pid.get_group(patient_id)['plan_type'].tolist())\n",
    "    event_time_list.append(grouping_pid.get_group(patient_id)['event_time'].agg('std'))\n",
    "    patient_payment_list.append(grouping_pid.get_group(patient_id)['patient_payment'].agg('mean'))\n",
    "    outcome_flag_list.append(grouping_pid.get_group(patient_id)['outcome_flag'].agg('mean'))\n",
    "    \n",
    "dicts = {'patient_id':patient_ids, 'event_name':event_name_list,'speciality':specialty_list,'plan_type':plan_type_list,\n",
    "        'event_time':event_time_list,'patient_payment':patient_payment_list}\n",
    "\n",
    "data = pd.DataFrame(data=dicts)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>event_name</th>\n",
       "      <th>speciality</th>\n",
       "      <th>plan_type</th>\n",
       "      <th>event_time</th>\n",
       "      <th>patient_payment</th>\n",
       "      <th>outcome_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>patient_1</td>\n",
       "      <td>[event_1, event_1, event_1, event_37, event_1,...</td>\n",
       "      <td>[spec_1, spec_1, spec_1, spec_1, spec_1, spec_...</td>\n",
       "      <td>[plan_1, plan_1, plan_1, plan_1, plan_1, plan_...</td>\n",
       "      <td>306.909565</td>\n",
       "      <td>0.207534</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>patient_4</td>\n",
       "      <td>[event_1, event_1, event_16, event_1, event_16...</td>\n",
       "      <td>[spec_1, spec_1, spec_1, spec_1, spec_1, spec_...</td>\n",
       "      <td>[plan_2, plan_2, plan_2, plan_2, plan_2, plan_...</td>\n",
       "      <td>344.725741</td>\n",
       "      <td>8.706540</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>patient_6</td>\n",
       "      <td>[event_1, event_1, event_1, event_1, event_1, ...</td>\n",
       "      <td>[spec_1, spec_1, spec_1, spec_1, spec_1, spec_...</td>\n",
       "      <td>[plan_1, plan_1, plan_1, plan_1, plan_1, plan_...</td>\n",
       "      <td>389.652368</td>\n",
       "      <td>0.145944</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>patient_7</td>\n",
       "      <td>[event_1, event_4, event_4, event_4, event_4, ...</td>\n",
       "      <td>[spec_1, spec_1, spec_1, spec_1, spec_1, spec_...</td>\n",
       "      <td>[plan_1, plan_1, plan_1, plan_1, plan_1, plan_...</td>\n",
       "      <td>303.649274</td>\n",
       "      <td>1.439409</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>patient_9</td>\n",
       "      <td>[event_1, event_3, event_2, event_3, event_1, ...</td>\n",
       "      <td>[spec_1, spec_1, spec_1, spec_1, spec_1, spec_...</td>\n",
       "      <td>[plan_1, plan_1, plan_1, plan_1, plan_1, plan_...</td>\n",
       "      <td>314.094013</td>\n",
       "      <td>13.101290</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  patient_id                                         event_name  \\\n",
       "0  patient_1  [event_1, event_1, event_1, event_37, event_1,...   \n",
       "1  patient_4  [event_1, event_1, event_16, event_1, event_16...   \n",
       "2  patient_6  [event_1, event_1, event_1, event_1, event_1, ...   \n",
       "3  patient_7  [event_1, event_4, event_4, event_4, event_4, ...   \n",
       "4  patient_9  [event_1, event_3, event_2, event_3, event_1, ...   \n",
       "\n",
       "                                          speciality  \\\n",
       "0  [spec_1, spec_1, spec_1, spec_1, spec_1, spec_...   \n",
       "1  [spec_1, spec_1, spec_1, spec_1, spec_1, spec_...   \n",
       "2  [spec_1, spec_1, spec_1, spec_1, spec_1, spec_...   \n",
       "3  [spec_1, spec_1, spec_1, spec_1, spec_1, spec_...   \n",
       "4  [spec_1, spec_1, spec_1, spec_1, spec_1, spec_...   \n",
       "\n",
       "                                           plan_type  event_time  \\\n",
       "0  [plan_1, plan_1, plan_1, plan_1, plan_1, plan_...  306.909565   \n",
       "1  [plan_2, plan_2, plan_2, plan_2, plan_2, plan_...  344.725741   \n",
       "2  [plan_1, plan_1, plan_1, plan_1, plan_1, plan_...  389.652368   \n",
       "3  [plan_1, plan_1, plan_1, plan_1, plan_1, plan_...  303.649274   \n",
       "4  [plan_1, plan_1, plan_1, plan_1, plan_1, plan_...  314.094013   \n",
       "\n",
       "   patient_payment  outcome_flag  \n",
       "0         0.207534           0.0  \n",
       "1         8.706540           0.0  \n",
       "2         0.145944           0.0  \n",
       "3         1.439409           0.0  \n",
       "4        13.101290           0.0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['outcome_flag'] = outcome_flag_list\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>event_name</th>\n",
       "      <th>speciality</th>\n",
       "      <th>plan_type</th>\n",
       "      <th>event_time</th>\n",
       "      <th>patient_payment</th>\n",
       "      <th>outcome_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>patient_1</td>\n",
       "      <td>event_1, event_1, event_1, event_37, event_1, ...</td>\n",
       "      <td>spec_1, spec_1, spec_1, spec_1, spec_1, spec_1...</td>\n",
       "      <td>plan_1, plan_1, plan_1, plan_1, plan_1, plan_1...</td>\n",
       "      <td>306.909565</td>\n",
       "      <td>0.207534</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>patient_4</td>\n",
       "      <td>event_1, event_1, event_16, event_1, event_16,...</td>\n",
       "      <td>spec_1, spec_1, spec_1, spec_1, spec_1, spec_1...</td>\n",
       "      <td>plan_2, plan_2, plan_2, plan_2, plan_2, plan_2...</td>\n",
       "      <td>344.725741</td>\n",
       "      <td>8.706540</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>patient_6</td>\n",
       "      <td>event_1, event_1, event_1, event_1, event_1, e...</td>\n",
       "      <td>spec_1, spec_1, spec_1, spec_1, spec_1, spec_1...</td>\n",
       "      <td>plan_1, plan_1, plan_1, plan_1, plan_1, plan_1...</td>\n",
       "      <td>389.652368</td>\n",
       "      <td>0.145944</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>patient_7</td>\n",
       "      <td>event_1, event_4, event_4, event_4, event_4, e...</td>\n",
       "      <td>spec_1, spec_1, spec_1, spec_1, spec_1, spec_1...</td>\n",
       "      <td>plan_1, plan_1, plan_1, plan_1, plan_1, plan_1...</td>\n",
       "      <td>303.649274</td>\n",
       "      <td>1.439409</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>patient_9</td>\n",
       "      <td>event_1, event_3, event_2, event_3, event_1, e...</td>\n",
       "      <td>spec_1, spec_1, spec_1, spec_1, spec_1, spec_1...</td>\n",
       "      <td>plan_1, plan_1, plan_1, plan_1, plan_1, plan_1...</td>\n",
       "      <td>314.094013</td>\n",
       "      <td>13.101290</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  patient_id                                         event_name  \\\n",
       "0  patient_1  event_1, event_1, event_1, event_37, event_1, ...   \n",
       "1  patient_4  event_1, event_1, event_16, event_1, event_16,...   \n",
       "2  patient_6  event_1, event_1, event_1, event_1, event_1, e...   \n",
       "3  patient_7  event_1, event_4, event_4, event_4, event_4, e...   \n",
       "4  patient_9  event_1, event_3, event_2, event_3, event_1, e...   \n",
       "\n",
       "                                          speciality  \\\n",
       "0  spec_1, spec_1, spec_1, spec_1, spec_1, spec_1...   \n",
       "1  spec_1, spec_1, spec_1, spec_1, spec_1, spec_1...   \n",
       "2  spec_1, spec_1, spec_1, spec_1, spec_1, spec_1...   \n",
       "3  spec_1, spec_1, spec_1, spec_1, spec_1, spec_1...   \n",
       "4  spec_1, spec_1, spec_1, spec_1, spec_1, spec_1...   \n",
       "\n",
       "                                           plan_type  event_time  \\\n",
       "0  plan_1, plan_1, plan_1, plan_1, plan_1, plan_1...  306.909565   \n",
       "1  plan_2, plan_2, plan_2, plan_2, plan_2, plan_2...  344.725741   \n",
       "2  plan_1, plan_1, plan_1, plan_1, plan_1, plan_1...  389.652368   \n",
       "3  plan_1, plan_1, plan_1, plan_1, plan_1, plan_1...  303.649274   \n",
       "4  plan_1, plan_1, plan_1, plan_1, plan_1, plan_1...  314.094013   \n",
       "\n",
       "   patient_payment  outcome_flag  \n",
       "0         0.207534           0.0  \n",
       "1         8.706540           0.0  \n",
       "2         0.145944           0.0  \n",
       "3         1.439409           0.0  \n",
       "4        13.101290           0.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['event_name'] = data['event_name'].astype('str').str.replace(\"'\",\"\")\n",
    "data['event_name'] = data['event_name'].astype('str').str.replace(\"]\",\"\")\n",
    "data['event_name'] = data['event_name'].astype('str').str.replace(\"[\",\"\")\n",
    "\n",
    "data['speciality'] = data['speciality'].astype('str').str.replace(\"'\",\"\")\n",
    "data['speciality'] = data['speciality'].astype('str').str.replace(\"]\",\"\")\n",
    "data['speciality'] = data['speciality'].astype('str').str.replace(\"[\",\"\")\n",
    "\n",
    "data['plan_type'] = data['plan_type'].astype('str').str.replace(\"'\",\"\")\n",
    "data['plan_type'] = data['plan_type'].astype('str').str.replace(\"]\",\"\")\n",
    "data['plan_type'] = data['plan_type'].astype('str').str.replace(\"[\",\"\")\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23831, 527)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.concat([data, \n",
    "          data.event_name.apply(lambda x: pd.Series(x.split(', ')).value_counts()).fillna(0)], \n",
    "          axis = 1)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23831, 772)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop('event_name', axis=1)\n",
    "\n",
    "data = pd.concat([data, \n",
    "          data.speciality.apply(lambda x: pd.Series(x.split(', ')).value_counts()).fillna(0)], \n",
    "          axis = 1)\n",
    "data = data.drop('speciality', axis=1)\n",
    "data = pd.concat([data, \n",
    "          data.plan_type.apply(lambda x: pd.Series(x.split(', ')).value_counts()).fillna(0)], \n",
    "          axis = 1)\n",
    "data = data.drop('plan_type', axis=1)\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "final_data = np.concatenate((e, s, p, np.array([data.event_time.values]).reshape(-1,1), \n",
    "                             np.array([data.patient_payment.values]).reshape(-1,1)), axis=1)\n",
    "final_data.shape\n",
    "\n",
    "X = final_data[0:16683]\n",
    "y = data[data['outcome_flag'].isnull()!=True]['outcome_flag']\n",
    "\n",
    "X_test = final_data[16683:]\n",
    "\n",
    "X.shape, y.shape, X_test.shape\n",
    "\n",
    "X = final_data[0:16683]\n",
    "y = data[data['outcome_flag'].isnull()!=True]['outcome_flag']\n",
    "\n",
    "X_test = final_data[16683:]\n",
    "\n",
    "X = np.nan_to_num(X)\n",
    "y = np.nan_to_num(y)\n",
    "X_test = np.nan_to_num(X_test)\n",
    "\n",
    "X.shape, y.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16683, 770), (16683,), (7148, 770))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data[data['outcome_flag'].isnull()!=True].drop(['patient_id','outcome_flag'], axis=1)\n",
    "y = data[data['outcome_flag'].isnull()!=True]['outcome_flag']\n",
    "\n",
    "X_test = data[data['outcome_flag'].isnull()==True].drop(['patient_id','outcome_flag'], axis=1)\n",
    "\n",
    "X.shape, y.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[100]\ttraining's auc: 0.929036\ttraining's binary_logloss: 0.279006\tvalid_1's auc: 0.718261\tvalid_1's binary_logloss: 0.371966\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "model = LGBMClassifier(n_estimator=5000,\n",
    "                       random_state=1994,\n",
    "                       learning_rate=0.05,\n",
    "                       reg_alpha=0.2,\n",
    "                       colsample_bytree=0.5,\n",
    "                       bagging_fraction=0.9)\n",
    "\n",
    "model.fit(x_train,y_train,\n",
    "          eval_set=[(x_train,y_train),(x_val, y_val.values)],\n",
    "          eval_metric='auc',\n",
    "          early_stopping_rounds=100,\n",
    "          verbose=200)\n",
    "\n",
    "pred_y = model.predict_proba(x_val)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7182612296928558\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2855,    6],\n",
       "       [ 470,    6]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix,roc_auc_score\n",
    "print(roc_auc_score(y_val, pred_y))\n",
    "confusion_matrix(y_val,pred_y>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's auc: 0.938073\ttraining's binary_logloss: 0.26188\tvalid_1's auc: 0.725126\tvalid_1's binary_logloss: 0.373617\n",
      "Early stopping, best iteration is:\n",
      "[129]\ttraining's auc: 0.915563\ttraining's binary_logloss: 0.284933\tvalid_1's auc: 0.728483\tvalid_1's binary_logloss: 0.372812\n",
      "err_lgm:  0.7284825728044027\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's auc: 0.940525\ttraining's binary_logloss: 0.258846\tvalid_1's auc: 0.723157\tvalid_1's binary_logloss: 0.377711\n",
      "Early stopping, best iteration is:\n",
      "[153]\ttraining's auc: 0.927058\ttraining's binary_logloss: 0.274134\tvalid_1's auc: 0.723684\tvalid_1's binary_logloss: 0.376388\n",
      "err_lgm:  0.7236843613850035\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's auc: 0.94213\ttraining's binary_logloss: 0.25828\tvalid_1's auc: 0.72629\tvalid_1's binary_logloss: 0.373581\n",
      "Early stopping, best iteration is:\n",
      "[132]\ttraining's auc: 0.916974\ttraining's binary_logloss: 0.284582\tvalid_1's auc: 0.733072\tvalid_1's binary_logloss: 0.371213\n",
      "err_lgm:  0.7330715432240312\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's auc: 0.941458\ttraining's binary_logloss: 0.257721\tvalid_1's auc: 0.713231\tvalid_1's binary_logloss: 0.381313\n",
      "Early stopping, best iteration is:\n",
      "[110]\ttraining's auc: 0.906715\ttraining's binary_logloss: 0.292471\tvalid_1's auc: 0.712457\tvalid_1's binary_logloss: 0.380086\n",
      "err_lgm:  0.7124570052740197\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's auc: 0.944828\ttraining's binary_logloss: 0.255024\tvalid_1's auc: 0.723765\tvalid_1's binary_logloss: 0.380148\n",
      "Early stopping, best iteration is:\n",
      "[182]\ttraining's auc: 0.940331\ttraining's binary_logloss: 0.261007\tvalid_1's auc: 0.724579\tvalid_1's binary_logloss: 0.379886\n",
      "err_lgm:  0.7245786516853934\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's auc: 0.938648\ttraining's binary_logloss: 0.260498\tvalid_1's auc: 0.739816\tvalid_1's binary_logloss: 0.37135\n",
      "Early stopping, best iteration is:\n",
      "[154]\ttraining's auc: 0.923677\ttraining's binary_logloss: 0.275866\tvalid_1's auc: 0.743969\tvalid_1's binary_logloss: 0.369141\n",
      "err_lgm:  0.7439692731024994\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's auc: 0.942375\ttraining's binary_logloss: 0.257919\tvalid_1's auc: 0.705764\tvalid_1's binary_logloss: 0.383018\n",
      "Early stopping, best iteration is:\n",
      "[85]\ttraining's auc: 0.891408\ttraining's binary_logloss: 0.305383\tvalid_1's auc: 0.709438\tvalid_1's binary_logloss: 0.380504\n",
      "err_lgm:  0.7094382376984526\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's auc: 0.940267\ttraining's binary_logloss: 0.259116\tvalid_1's auc: 0.732319\tvalid_1's binary_logloss: 0.372792\n",
      "Early stopping, best iteration is:\n",
      "[86]\ttraining's auc: 0.894646\ttraining's binary_logloss: 0.303397\tvalid_1's auc: 0.736717\tvalid_1's binary_logloss: 0.372585\n",
      "err_lgm:  0.7367170489499211\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's auc: 0.936174\ttraining's binary_logloss: 0.26366\tvalid_1's auc: 0.743341\tvalid_1's binary_logloss: 0.369428\n",
      "[400]\ttraining's auc: 0.973681\ttraining's binary_logloss: 0.208767\tvalid_1's auc: 0.73513\tvalid_1's binary_logloss: 0.376222\n",
      "Early stopping, best iteration is:\n",
      "[226]\ttraining's auc: 0.943279\ttraining's binary_logloss: 0.255536\tvalid_1's auc: 0.744836\tvalid_1's binary_logloss: 0.368951\n",
      "err_lgm:  0.7448360079720747\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "[200]\ttraining's auc: 0.939488\ttraining's binary_logloss: 0.260586\tvalid_1's auc: 0.740715\tvalid_1's binary_logloss: 0.367797\n",
      "Early stopping, best iteration is:\n",
      "[133]\ttraining's auc: 0.915924\ttraining's binary_logloss: 0.284665\tvalid_1's auc: 0.742325\tvalid_1's binary_logloss: 0.368388\n",
      "err_lgm:  0.7423245740354596\n"
     ]
    }
   ],
   "source": [
    "err = []\n",
    "y_pred_tot_lgm = []\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "fold = StratifiedKFold(n_splits=10,shuffle=True,random_state=1994)\n",
    "i = 1\n",
    "for train_index, test_index in fold.split(X, y):\n",
    "    x_train, x_val = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_val = y[train_index], y[test_index]\n",
    "    m = LGBMClassifier(boosting_type='gbdt',\n",
    "                       max_depth=5,\n",
    "                       learning_rate=0.08,\n",
    "                       n_estimators=5000,\n",
    "                       min_child_weight=0.01,\n",
    "                       colsample_bytree=0.5,\n",
    "                       random_state=1994)\n",
    "    m.fit(x_train, y_train,\n",
    "          eval_set=[(x_train,y_train),(x_val, y_val)],\n",
    "          early_stopping_rounds=200,\n",
    "          eval_metric='auc',\n",
    "          verbose=200)\n",
    "    pred_y = m.predict_proba(x_val)[:,1]\n",
    "    print(\"err_lgm: \",roc_auc_score(y_val,pred_y))\n",
    "    err.append(roc_auc_score(y_val, pred_y))\n",
    "    pred_test = m.predict_proba(X_test)[:,1]\n",
    "    i = i + 1\n",
    "    y_pred_tot_lgm.append(pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7299559276131257"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(err,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.694231\tvalidation_1-auc:0.63656\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 200 rounds.\n",
      "[200]\tvalidation_0-auc:0.934484\tvalidation_1-auc:0.718551\n",
      "Stopping. Best iteration:\n",
      "[103]\tvalidation_0-auc:0.89601\tvalidation_1-auc:0.721922\n",
      "\n",
      "err_xgb:  0.721921577619812\n",
      "[0]\tvalidation_0-auc:0.692377\tvalidation_1-auc:0.654694\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 200 rounds.\n",
      "[200]\tvalidation_0-auc:0.941172\tvalidation_1-auc:0.723406\n",
      "Stopping. Best iteration:\n",
      "[87]\tvalidation_0-auc:0.886379\tvalidation_1-auc:0.724467\n",
      "\n",
      "err_xgb:  0.7244668653978447\n",
      "[0]\tvalidation_0-auc:0.696095\tvalidation_1-auc:0.667162\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 200 rounds.\n",
      "[200]\tvalidation_0-auc:0.941616\tvalidation_1-auc:0.7295\n",
      "Stopping. Best iteration:\n",
      "[154]\tvalidation_0-auc:0.92548\tvalidation_1-auc:0.731249\n",
      "\n",
      "err_xgb:  0.7312485668424674\n",
      "[0]\tvalidation_0-auc:0.696577\tvalidation_1-auc:0.661758\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 200 rounds.\n",
      "[200]\tvalidation_0-auc:0.940039\tvalidation_1-auc:0.712984\n",
      "Stopping. Best iteration:\n",
      "[102]\tvalidation_0-auc:0.899216\tvalidation_1-auc:0.717272\n",
      "\n",
      "err_xgb:  0.7172724145838111\n",
      "[0]\tvalidation_0-auc:0.698007\tvalidation_1-auc:0.653887\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 200 rounds.\n",
      "[200]\tvalidation_0-auc:0.940591\tvalidation_1-auc:0.723223\n",
      "Stopping. Best iteration:\n",
      "[118]\tvalidation_0-auc:0.905973\tvalidation_1-auc:0.726058\n",
      "\n",
      "err_xgb:  0.7260576702591149\n",
      "[0]\tvalidation_0-auc:0.695171\tvalidation_1-auc:0.665805\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 200 rounds.\n",
      "[200]\tvalidation_0-auc:0.936546\tvalidation_1-auc:0.739759\n",
      "[400]\tvalidation_0-auc:0.97398\tvalidation_1-auc:0.735342\n",
      "Stopping. Best iteration:\n",
      "[212]\tvalidation_0-auc:0.940425\tvalidation_1-auc:0.741071\n",
      "\n",
      "err_xgb:  0.7410714285714286\n",
      "[0]\tvalidation_0-auc:0.698018\tvalidation_1-auc:0.629712\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 200 rounds.\n",
      "[200]\tvalidation_0-auc:0.939598\tvalidation_1-auc:0.707476\n",
      "Stopping. Best iteration:\n",
      "[148]\tvalidation_0-auc:0.919796\tvalidation_1-auc:0.711219\n",
      "\n",
      "err_xgb:  0.7112194702195707\n",
      "[0]\tvalidation_0-auc:0.695103\tvalidation_1-auc:0.678685\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 200 rounds.\n",
      "[200]\tvalidation_0-auc:0.940004\tvalidation_1-auc:0.735242\n",
      "Stopping. Best iteration:\n",
      "[110]\tvalidation_0-auc:0.904106\tvalidation_1-auc:0.742892\n",
      "\n",
      "err_xgb:  0.7428919507390297\n",
      "[0]\tvalidation_0-auc:0.693745\tvalidation_1-auc:0.661483\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 200 rounds.\n",
      "[200]\tvalidation_0-auc:0.93444\tvalidation_1-auc:0.735496\n",
      "[400]\tvalidation_0-auc:0.972053\tvalidation_1-auc:0.735674\n",
      "Stopping. Best iteration:\n",
      "[276]\tvalidation_0-auc:0.951783\tvalidation_1-auc:0.739249\n",
      "\n",
      "err_xgb:  0.739248643480064\n",
      "[0]\tvalidation_0-auc:0.694482\tvalidation_1-auc:0.666381\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 200 rounds.\n",
      "[200]\tvalidation_0-auc:0.94113\tvalidation_1-auc:0.730571\n",
      "[400]\tvalidation_0-auc:0.975601\tvalidation_1-auc:0.736757\n",
      "[600]\tvalidation_0-auc:0.989972\tvalidation_1-auc:0.731302\n",
      "Stopping. Best iteration:\n",
      "[456]\tvalidation_0-auc:0.981076\tvalidation_1-auc:0.738552\n",
      "\n",
      "err_xgb:  0.7385516629609576\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "errxgb = []\n",
    "y_pred_tot_xgb = []\n",
    "\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "\n",
    "fold = StratifiedKFold(n_splits=10,shuffle=True,random_state=1994)\n",
    "i = 1\n",
    "for train_index, test_index in fold.split(X,y):\n",
    "    x_train, x_val = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_val = y[train_index], y[test_index]\n",
    "    m = XGBClassifier(boosting_type='gbdt',\n",
    "                      max_depth=5,\n",
    "                      learning_rate=0.07,\n",
    "                      n_estimators=5000,\n",
    "                      random_state=1994)\n",
    "    m.fit(x_train, y_train,\n",
    "          eval_set=[(x_train,y_train),(x_val, y_val)],\n",
    "          early_stopping_rounds=200,\n",
    "          eval_metric='auc',\n",
    "          verbose=200)\n",
    "    pred_y = m.predict_proba(x_val)[:,-1]\n",
    "    print(\"err_xgb: \",roc_auc_score(y_val,pred_y))\n",
    "    errxgb.append(roc_auc_score(y_val, pred_y))\n",
    "    pred_test = m.predict_proba(X_test)[:,-1]\n",
    "    i = i + 1\n",
    "    y_pred_tot_xgb.append(pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\ttest: 0.5013648\ttest1: 0.4904461\tbest: 0.4904461 (0)\ttotal: 109ms\tremaining: 9m 4s\n",
      "200:\ttest: 0.7790814\ttest1: 0.7181001\tbest: 0.7181001 (200)\ttotal: 10.6s\tremaining: 4m 13s\n",
      "400:\ttest: 0.8260051\ttest1: 0.7317458\tbest: 0.7320347 (396)\ttotal: 20.8s\tremaining: 3m 58s\n",
      "600:\ttest: 0.8703218\ttest1: 0.7357253\tbest: 0.7357253 (600)\ttotal: 31s\tremaining: 3m 46s\n",
      "800:\ttest: 0.9001024\ttest1: 0.7363286\tbest: 0.7363800 (788)\ttotal: 41s\tremaining: 3m 35s\n",
      "1000:\ttest: 0.9206709\ttest1: 0.7373171\tbest: 0.7377214 (991)\ttotal: 51.1s\tremaining: 3m 23s\n",
      "1200:\ttest: 0.9370421\ttest1: 0.7396791\tbest: 0.7400064 (1195)\ttotal: 1m 1s\tremaining: 3m 13s\n",
      "1400:\ttest: 0.9517233\ttest1: 0.7396662\tbest: 0.7410526 (1344)\ttotal: 1m 11s\tremaining: 3m 3s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.7410526316\n",
      "bestIteration = 1344\n",
      "\n",
      "Shrink model to first 1345 iterations.\n",
      "err_cb:  0.7410526315789474\n",
      "0:\ttest: 0.5099030\ttest1: 0.5152825\tbest: 0.5152825 (0)\ttotal: 49.3ms\tremaining: 4m 6s\n",
      "200:\ttest: 0.7750960\ttest1: 0.7569842\tbest: 0.7575818 (191)\ttotal: 10.4s\tremaining: 4m 9s\n",
      "400:\ttest: 0.8204718\ttest1: 0.7654656\tbest: 0.7658639 (391)\ttotal: 20.6s\tremaining: 3m 56s\n",
      "600:\ttest: 0.8675853\ttest1: 0.7649002\tbest: 0.7669884 (472)\ttotal: 30.7s\tremaining: 3m 45s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.7669883574\n",
      "bestIteration = 472\n",
      "\n",
      "Shrink model to first 473 iterations.\n",
      "err_cb:  0.7669883574494333\n",
      "0:\ttest: 0.5804564\ttest1: 0.6003155\tbest: 0.6003155 (0)\ttotal: 52.8ms\tremaining: 4m 24s\n",
      "200:\ttest: 0.7805503\ttest1: 0.7075514\tbest: 0.7086504 (197)\ttotal: 10.5s\tremaining: 4m 11s\n",
      "400:\ttest: 0.8300941\ttest1: 0.7085922\tbest: 0.7103441 (330)\ttotal: 20.7s\tremaining: 3m 57s\n",
      "600:\ttest: 0.8721214\ttest1: 0.7098011\tbest: 0.7108160 (518)\ttotal: 31s\tremaining: 3m 47s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.710816035\n",
      "bestIteration = 518\n",
      "\n",
      "Shrink model to first 519 iterations.\n",
      "err_cb:  0.710816034960921\n",
      "0:\ttest: 0.5042106\ttest1: 0.4944662\tbest: 0.4944662 (0)\ttotal: 50.3ms\tremaining: 4m 11s\n",
      "200:\ttest: 0.7771471\ttest1: 0.7221421\tbest: 0.7221874 (199)\ttotal: 10.7s\tremaining: 4m 15s\n",
      "400:\ttest: 0.8276745\ttest1: 0.7310310\tbest: 0.7310310 (400)\ttotal: 21s\tremaining: 4m 1s\n",
      "600:\ttest: 0.8723389\ttest1: 0.7362610\tbest: 0.7366036 (588)\ttotal: 31.4s\tremaining: 3m 49s\n",
      "800:\ttest: 0.9014136\ttest1: 0.7371854\tbest: 0.7379224 (702)\ttotal: 41.6s\tremaining: 3m 38s\n",
      "1000:\ttest: 0.9201561\ttest1: 0.7407668\tbest: 0.7410060 (987)\ttotal: 51.8s\tremaining: 3m 26s\n",
      "1200:\ttest: 0.9380679\ttest1: 0.7437923\tbest: 0.7446974 (1184)\ttotal: 1m 2s\tremaining: 3m 17s\n",
      "1400:\ttest: 0.9522740\ttest1: 0.7450206\tbest: 0.7456024 (1333)\ttotal: 1m 13s\tremaining: 3m 7s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.74560241\n",
      "bestIteration = 1333\n",
      "\n",
      "Shrink model to first 1334 iterations.\n",
      "err_cb:  0.745602410027992\n",
      "0:\ttest: 0.5040838\ttest1: 0.5032453\tbest: 0.5032453 (0)\ttotal: 46ms\tremaining: 3m 50s\n",
      "200:\ttest: 0.7772436\ttest1: 0.7325632\tbest: 0.7331321 (189)\ttotal: 10.5s\tremaining: 4m 10s\n",
      "400:\ttest: 0.8212533\ttest1: 0.7411030\tbest: 0.7415555 (385)\ttotal: 20.6s\tremaining: 3m 56s\n",
      "600:\ttest: 0.8677418\ttest1: 0.7429713\tbest: 0.7448266 (486)\ttotal: 30.9s\tremaining: 3m 46s\n",
      "800:\ttest: 0.8976322\ttest1: 0.7463846\tbest: 0.7470182 (714)\ttotal: 41s\tremaining: 3m 34s\n",
      "1000:\ttest: 0.9198626\ttest1: 0.7443095\tbest: 0.7472897 (871)\ttotal: 51.1s\tremaining: 3m 24s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.7472896882\n",
      "bestIteration = 871\n",
      "\n",
      "Shrink model to first 872 iterations.\n",
      "err_cb:  0.7472896882090931\n",
      "0:\ttest: 0.5062817\ttest1: 0.4970844\tbest: 0.4970844 (0)\ttotal: 45.5ms\tremaining: 3m 47s\n",
      "200:\ttest: 0.7784239\ttest1: 0.7039182\tbest: 0.7039182 (200)\ttotal: 10.5s\tremaining: 4m 11s\n",
      "400:\ttest: 0.8265606\ttest1: 0.7174746\tbest: 0.7181470 (392)\ttotal: 20.7s\tremaining: 3m 57s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.7181469677\n",
      "bestIteration = 392\n",
      "\n",
      "Shrink model to first 393 iterations.\n",
      "err_cb:  0.7181469677477745\n",
      "0:\ttest: 0.5805382\ttest1: 0.5578814\tbest: 0.5578814 (0)\ttotal: 52.7ms\tremaining: 4m 23s\n",
      "200:\ttest: 0.7799100\ttest1: 0.7251547\tbest: 0.7265510 (192)\ttotal: 10.5s\tremaining: 4m 11s\n",
      "400:\ttest: 0.8265160\ttest1: 0.7330351\tbest: 0.7330674 (399)\ttotal: 20.7s\tremaining: 3m 57s\n",
      "600:\ttest: 0.8729736\ttest1: 0.7374828\tbest: 0.7391183 (543)\ttotal: 30.9s\tremaining: 3m 46s\n",
      "800:\ttest: 0.9022996\ttest1: 0.7393188\tbest: 0.7401462 (762)\ttotal: 41.1s\tremaining: 3m 35s\n",
      "1000:\ttest: 0.9256422\ttest1: 0.7422925\tbest: 0.7433268 (933)\ttotal: 51.3s\tremaining: 3m 24s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.7433268471\n",
      "bestIteration = 933\n",
      "\n",
      "Shrink model to first 934 iterations.\n",
      "err_cb:  0.7433268471170816\n",
      "0:\ttest: 0.5116917\ttest1: 0.5235055\tbest: 0.5235055 (0)\ttotal: 47.8ms\tremaining: 3m 59s\n",
      "200:\ttest: 0.7750668\ttest1: 0.7194981\tbest: 0.7199894 (194)\ttotal: 10.5s\tremaining: 4m 10s\n",
      "400:\ttest: 0.8251681\ttest1: 0.7358602\tbest: 0.7359701 (396)\ttotal: 20.7s\tremaining: 3m 57s\n",
      "600:\ttest: 0.8684390\ttest1: 0.7415167\tbest: 0.7415167 (600)\ttotal: 31s\tremaining: 3m 46s\n",
      "800:\ttest: 0.8977688\ttest1: 0.7460161\tbest: 0.7467725 (759)\ttotal: 41s\tremaining: 3m 35s\n",
      "1000:\ttest: 0.9207048\ttest1: 0.7532307\tbest: 0.7532307 (1000)\ttotal: 51.2s\tremaining: 3m 24s\n",
      "1200:\ttest: 0.9378110\ttest1: 0.7529915\tbest: 0.7537673 (1008)\ttotal: 1m 1s\tremaining: 3m 14s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.7537672849\n",
      "bestIteration = 1008\n",
      "\n",
      "Shrink model to first 1009 iterations.\n",
      "err_cb:  0.7537672849043553\n",
      "0:\ttest: 0.5623017\ttest1: 0.5362280\tbest: 0.5362280 (0)\ttotal: 48.3ms\tremaining: 4m 1s\n",
      "200:\ttest: 0.7768829\ttest1: 0.7144944\tbest: 0.7144944 (200)\ttotal: 10.7s\tremaining: 4m 14s\n",
      "400:\ttest: 0.8259248\ttest1: 0.7277276\tbest: 0.7277276 (400)\ttotal: 20.9s\tremaining: 4m\n",
      "600:\ttest: 0.8692198\ttest1: 0.7285680\tbest: 0.7288654 (599)\ttotal: 31.4s\tremaining: 3m 49s\n",
      "800:\ttest: 0.9010615\ttest1: 0.7261438\tbest: 0.7288977 (633)\ttotal: 41.7s\tremaining: 3m 38s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.7288977096\n",
      "bestIteration = 633\n",
      "\n",
      "Shrink model to first 634 iterations.\n",
      "err_cb:  0.7288977095683542\n",
      "0:\ttest: 0.5020110\ttest1: 0.5013673\tbest: 0.5013673 (0)\ttotal: 46.3ms\tremaining: 3m 51s\n",
      "200:\ttest: 0.7796581\ttest1: 0.7078423\tbest: 0.7081009 (198)\ttotal: 10.5s\tremaining: 4m 11s\n",
      "400:\ttest: 0.8283396\ttest1: 0.7154771\tbest: 0.7155546 (378)\ttotal: 20.8s\tremaining: 3m 58s\n",
      "600:\ttest: 0.8726958\ttest1: 0.7124257\tbest: 0.7164403 (482)\ttotal: 31.5s\tremaining: 3m 50s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.7164402956\n",
      "bestIteration = 482\n",
      "\n",
      "Shrink model to first 483 iterations.\n",
      "err_cb:  0.7164402955645917\n",
      "0:\ttest: 0.5080994\ttest1: 0.5240065\tbest: 0.5240065 (0)\ttotal: 47.1ms\tremaining: 3m 55s\n",
      "200:\ttest: 0.7782054\ttest1: 0.7051013\tbest: 0.7062326 (189)\ttotal: 10.5s\tremaining: 4m 10s\n",
      "400:\ttest: 0.8263853\ttest1: 0.7136023\tbest: 0.7136023 (400)\ttotal: 20.7s\tremaining: 3m 57s\n",
      "600:\ttest: 0.8693820\ttest1: 0.7182439\tbest: 0.7184056 (599)\ttotal: 30.9s\tremaining: 3m 46s\n",
      "800:\ttest: 0.9005043\ttest1: 0.7183409\tbest: 0.7201963 (752)\ttotal: 41.2s\tremaining: 3m 35s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.7201962673\n",
      "bestIteration = 752\n",
      "\n",
      "Shrink model to first 753 iterations.\n",
      "err_cb:  0.7201962673010661\n",
      "0:\ttest: 0.5203024\ttest1: 0.5237835\tbest: 0.5237835 (0)\ttotal: 49.4ms\tremaining: 4m 6s\n",
      "200:\ttest: 0.7729308\ttest1: 0.7397713\tbest: 0.7411676 (186)\ttotal: 10.6s\tremaining: 4m 12s\n",
      "400:\ttest: 0.8201247\ttest1: 0.7468048\tbest: 0.7468242 (396)\ttotal: 20.8s\tremaining: 3m 58s\n",
      "600:\ttest: 0.8645845\ttest1: 0.7476259\tbest: 0.7483693 (587)\ttotal: 31.1s\tremaining: 3m 47s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.7483692877\n",
      "bestIteration = 587\n",
      "\n",
      "Shrink model to first 588 iterations.\n",
      "err_cb:  0.7483692876583036\n",
      "0:\ttest: 0.5065627\ttest1: 0.4962408\tbest: 0.4962408 (0)\ttotal: 46.1ms\tremaining: 3m 50s\n",
      "200:\ttest: 0.7812176\ttest1: 0.7089477\tbest: 0.7114366 (141)\ttotal: 10.6s\tremaining: 4m 13s\n",
      "400:\ttest: 0.8261926\ttest1: 0.7153284\tbest: 0.7153284 (400)\ttotal: 21s\tremaining: 4m\n",
      "600:\ttest: 0.8720429\ttest1: 0.7236355\tbest: 0.7236355 (600)\ttotal: 31.5s\tremaining: 3m 50s\n",
      "800:\ttest: 0.9003858\ttest1: 0.7262731\tbest: 0.7262731 (800)\ttotal: 41.7s\tremaining: 3m 38s\n",
      "1000:\ttest: 0.9223249\ttest1: 0.7273591\tbest: 0.7273591 (1000)\ttotal: 51.9s\tremaining: 3m 27s\n",
      "1200:\ttest: 0.9384898\ttest1: 0.7280250\tbest: 0.7290981 (1058)\ttotal: 1m 2s\tremaining: 3m 16s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.7290981143\n",
      "bestIteration = 1058\n",
      "\n",
      "Shrink model to first 1059 iterations.\n",
      "err_cb:  0.7290981142565308\n",
      "0:\ttest: 0.5121994\ttest1: 0.5330118\tbest: 0.5330118 (0)\ttotal: 48.3ms\tremaining: 4m 1s\n",
      "200:\ttest: 0.7750944\ttest1: 0.7585382\tbest: 0.7588938 (196)\ttotal: 10.5s\tremaining: 4m 10s\n",
      "400:\ttest: 0.8240302\ttest1: 0.7800785\tbest: 0.7803177 (399)\ttotal: 20.7s\tremaining: 3m 56s\n",
      "600:\ttest: 0.8698284\ttest1: 0.7851145\tbest: 0.7851145 (600)\ttotal: 33.7s\tremaining: 4m 7s\n",
      "800:\ttest: 0.9002111\ttest1: 0.7861423\tbest: 0.7870345 (721)\ttotal: 43.9s\tremaining: 3m 50s\n",
      "1000:\ttest: 0.9230860\ttest1: 0.7859225\tbest: 0.7873318 (909)\ttotal: 54.2s\tremaining: 3m 36s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.7873318378\n",
      "bestIteration = 909\n",
      "\n",
      "Shrink model to first 910 iterations.\n",
      "err_cb:  0.7873318378402839\n",
      "0:\ttest: 0.5099295\ttest1: 0.5190126\tbest: 0.5190126 (0)\ttotal: 47.2ms\tremaining: 3m 56s\n",
      "200:\ttest: 0.7784236\ttest1: 0.6819448\tbest: 0.6825848 (198)\ttotal: 10.7s\tremaining: 4m 15s\n",
      "400:\ttest: 0.8272745\ttest1: 0.6909049\tbest: 0.6909372 (398)\ttotal: 21s\tremaining: 4m 1s\n",
      "600:\ttest: 0.8696787\ttest1: 0.6964709\tbest: 0.6968524 (567)\ttotal: 31.3s\tremaining: 3m 49s\n",
      "800:\ttest: 0.9005236\ttest1: 0.7015263\tbest: 0.7018819 (793)\ttotal: 41.6s\tremaining: 3m 38s\n",
      "1000:\ttest: 0.9203300\ttest1: 0.7041639\tbest: 0.7047005 (895)\ttotal: 51.9s\tremaining: 3m 27s\n",
      "1200:\ttest: 0.9370703\ttest1: 0.7090124\tbest: 0.7090124 (1200)\ttotal: 1m 2s\tremaining: 3m 16s\n",
      "1400:\ttest: 0.9510058\ttest1: 0.7108871\tbest: 0.7113914 (1373)\ttotal: 1m 12s\tremaining: 3m 7s\n",
      "1600:\ttest: 0.9612523\ttest1: 0.7126843\tbest: 0.7129429 (1584)\ttotal: 1m 23s\tremaining: 2m 57s\n",
      "1800:\ttest: 0.9691679\ttest1: 0.7096912\tbest: 0.7133114 (1623)\ttotal: 1m 33s\tremaining: 2m 46s\n",
      "Stopped by overfitting detector  (200 iterations wait)\n",
      "\n",
      "bestTest = 0.7133113966\n",
      "bestIteration = 1623\n",
      "\n",
      "Shrink model to first 1624 iterations.\n",
      "err_cb:  0.7133113965620898\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier,Pool, cv\n",
    "errCB = []\n",
    "y_pred_tot_cb = []\n",
    "from sklearn.model_selection import KFold,StratifiedKFold\n",
    "\n",
    "fold = StratifiedKFold(n_splits=15,shuffle=True,random_state=1994)\n",
    "i = 1\n",
    "for train_index, test_index in fold.split(X,y):\n",
    "    x_train, x_val = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_val = y[train_index], y[test_index]\n",
    "    m = CatBoostClassifier(n_estimators=5000,\n",
    "                           random_state=1994,\n",
    "                           eval_metric='AUC',\n",
    "                           learning_rate=0.03)\n",
    "    m.fit(x_train, y_train,\n",
    "          eval_set=[(x_train,y_train),(x_val, y_val)],\n",
    "          early_stopping_rounds=200,\n",
    "          verbose=200)\n",
    "    pred_y = m.predict_proba(x_val)[:,-1]\n",
    "    print(\"err_cb: \",roc_auc_score(y_val,pred_y))\n",
    "    errCB.append(roc_auc_score(y_val,pred_y))\n",
    "    pred_test = m.predict_proba(X_test)[:,-1]\n",
    "    i = i + 1\n",
    "    y_pred_tot_cb.append(pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7324644315767745"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.mean(errxgb, 0) + np.mean(err, 0) + np.mean(errCB, 0))/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7148, 2)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['patient_id'] = data[data['outcome_flag'].isnull()==True]['patient_id']\n",
    "submission['outcome_flag'] = (np.mean(y_pred_tot_lgm, 0) + np.mean(y_pred_tot_cb, 0) + np.mean(y_pred_tot_xgb, 0))/3\n",
    "submission.to_excel('rfr_lrg.xlsx',sheet_name='Sheet1', index=False)\n",
    "submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7148, 2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission['outcome_flag'] = (np.mean(y_pred_tot_lgm, 0) >= 0.25).astype(int)\n",
    "submission['outcome_flag'].value_counts(normalize=True)\n",
    "submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>event_name</th>\n",
       "      <th>event_time</th>\n",
       "      <th>specialty</th>\n",
       "      <th>plan_type</th>\n",
       "      <th>patient_payment</th>\n",
       "      <th>outcome_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>patient_2</td>\n",
       "      <td>event_1</td>\n",
       "      <td>164</td>\n",
       "      <td>spec_1</td>\n",
       "      <td>plan_2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>patient_3</td>\n",
       "      <td>event_1</td>\n",
       "      <td>420</td>\n",
       "      <td>spec_1</td>\n",
       "      <td>plan_2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>patient_5</td>\n",
       "      <td>event_1</td>\n",
       "      <td>623</td>\n",
       "      <td>spec_1</td>\n",
       "      <td>plan_2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>patient_8</td>\n",
       "      <td>event_1</td>\n",
       "      <td>162</td>\n",
       "      <td>spec_1</td>\n",
       "      <td>plan_1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>patient_14</td>\n",
       "      <td>event_1</td>\n",
       "      <td>243</td>\n",
       "      <td>spec_1</td>\n",
       "      <td>plan_2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id event_name  event_time specialty plan_type  patient_payment  \\\n",
       "0   patient_2    event_1         164    spec_1    plan_2              0.0   \n",
       "1   patient_3    event_1         420    spec_1    plan_2              0.0   \n",
       "2   patient_5    event_1         623    spec_1    plan_2              0.0   \n",
       "3   patient_8    event_1         162    spec_1    plan_1              0.0   \n",
       "4  patient_14    event_1         243    spec_1    plan_2              0.0   \n",
       "\n",
       "   outcome_flag  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             0  \n",
       "4             1  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_new = pd.merge(test, submission, on=['patient_id'], how='left')\n",
    "test_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6256395, 7)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findClosest(arr, n, target):\n",
    "    if (target <= arr[0]): \n",
    "        return arr[0] \n",
    "    if (target >= arr[n - 1]): \n",
    "        return arr[n - 1]\n",
    "    i = 0; j = n; mid = 0\n",
    "    while (i < j):  \n",
    "        mid = int((i + j) / 2)\n",
    "        if (arr[mid] == target):\n",
    "            return arr[mid]\n",
    "        if (target < arr[mid]) :\n",
    "            if (mid > 0 and target > arr[mid - 1]): \n",
    "                return getClosest(arr[mid - 1], arr[mid], target)\n",
    "            j = mid\n",
    "        else : \n",
    "            if (mid < n - 1 and target < arr[mid + 1]): \n",
    "                return getClosest(arr[mid], arr[mid + 1], target)\n",
    "            i = mid + 1\n",
    "    return arr[mid]\n",
    "\n",
    "def getClosest(val1, val2, target): \n",
    "    if (target - val1 >= val2 - target): \n",
    "        return val2 \n",
    "    else: \n",
    "        return val1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "time0 = [i*30 for i in range(1,37)]\n",
    "time1 = [i*30 for i in range(1,19)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>event_name</th>\n",
       "      <th>event_time</th>\n",
       "      <th>specialty</th>\n",
       "      <th>plan_type</th>\n",
       "      <th>patient_payment</th>\n",
       "      <th>outcome_flag</th>\n",
       "      <th>event_time_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>patient_2</td>\n",
       "      <td>event_1</td>\n",
       "      <td>164</td>\n",
       "      <td>spec_1</td>\n",
       "      <td>plan_2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>patient_3</td>\n",
       "      <td>event_1</td>\n",
       "      <td>420</td>\n",
       "      <td>spec_1</td>\n",
       "      <td>plan_2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>patient_5</td>\n",
       "      <td>event_1</td>\n",
       "      <td>623</td>\n",
       "      <td>spec_1</td>\n",
       "      <td>plan_2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>patient_8</td>\n",
       "      <td>event_1</td>\n",
       "      <td>162</td>\n",
       "      <td>spec_1</td>\n",
       "      <td>plan_1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>patient_14</td>\n",
       "      <td>event_1</td>\n",
       "      <td>243</td>\n",
       "      <td>spec_1</td>\n",
       "      <td>plan_2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   patient_id event_name  event_time specialty plan_type  patient_payment  \\\n",
       "0   patient_2    event_1         164    spec_1    plan_2              0.0   \n",
       "1   patient_3    event_1         420    spec_1    plan_2              0.0   \n",
       "2   patient_5    event_1         623    spec_1    plan_2              0.0   \n",
       "3   patient_8    event_1         162    spec_1    plan_1              0.0   \n",
       "4  patient_14    event_1         243    spec_1    plan_2              0.0   \n",
       "\n",
       "   outcome_flag  event_time_range  \n",
       "0             0               150  \n",
       "1             0               420  \n",
       "2             0               630  \n",
       "3             0               150  \n",
       "4             1               240  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_new['event_time_range'] = test_new['event_time'].apply(lambda x: findClosest(time0, len(time0), x))\n",
    "test_new.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fitness Value Calculations for Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((14446880, 7), (6256395, 8))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/pandas/core/frame.py:7138: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(20703275, 7)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = train.append(test_new)\n",
    "df = df.drop('event_time_range', axis=1)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_name = df.drop_duplicates('event_name')['event_name']\n",
    "event_name = 'recency__event_name__' + event_name\n",
    "\n",
    "specialty = df.drop_duplicates('specialty')['specialty']\n",
    "specialty = 'recency__specialty__' + specialty\n",
    "\n",
    "plan_type = df.drop_duplicates('plan_type')['plan_type']\n",
    "plan_type = 'recency__event_name__' + plan_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_fitness = pd.DataFrame()\n",
    "new_fitness['feature_name'] = (event_name).append(specialty).append(plan_type)\n",
    "new_fitness.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(768, 1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_fitness = new_fitness.drop_duplicates('feature_name').reset_index()\n",
    "new_fitness = new_fitness.drop('index', axis=1)\n",
    "new_fitness.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recency_attributes(feature_name):\n",
    "    column = feature_name.split('__')[1]\n",
    "    value = feature_name.split('__')[2]\n",
    "\n",
    "    patient_level_feature = pd.DataFrame(df[df[column]==value][['patient_id', 'outcome_flag', 'event_time']]\n",
    "                                         .groupby(['patient_id', 'outcome_flag'])['event_time'].min(). reset_index())\n",
    "    patient_level_feature.columns = ['patient_id', 'outcome_flag', 'feature_value']\n",
    "\n",
    "\n",
    "    avg1 = patient_level_feature[(patient_level_feature['outcome_flag']==1) & (patient_level_feature['feature_value']!=9999999999)]['feature_value'].mean()\n",
    "    sd1 = patient_level_feature[(patient_level_feature['outcome_flag']==1) & (patient_level_feature['feature_value']!=9999999999)]['feature_value'].std()\n",
    "    avg0 = patient_level_feature[(patient_level_feature['outcome_flag']==0) & (patient_level_feature['feature_value']!=9999999999)]['feature_value'].mean()\n",
    "    sd0 = patient_level_feature[(patient_level_feature['outcome_flag']==0) & (patient_level_feature['feature_value']!=9999999999)]['feature_value'].std()\n",
    "    \n",
    "    return avg1, avg0, sd1, sd0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_name</th>\n",
       "      <th>numerics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>recency__event_name__event_1</td>\n",
       "      <td>(418.33673469387753, 401.6289401836684, 315.91...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>recency__event_name__event_2</td>\n",
       "      <td>(336.0029239766082, 312.6845727715293, 312.016...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>recency__event_name__event_3</td>\n",
       "      <td>(436.88235294117646, 208.28947368421052, 277.8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>recency__event_name__event_4</td>\n",
       "      <td>(334.8421052631579, 324.51372549019607, 223.50...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>recency__event_name__event_5</td>\n",
       "      <td>(484.264, 457.71407185628743, 295.132997466478...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   feature_name  \\\n",
       "0  recency__event_name__event_1   \n",
       "1  recency__event_name__event_2   \n",
       "2  recency__event_name__event_3   \n",
       "3  recency__event_name__event_4   \n",
       "4  recency__event_name__event_5   \n",
       "\n",
       "                                            numerics  \n",
       "0  (418.33673469387753, 401.6289401836684, 315.91...  \n",
       "1  (336.0029239766082, 312.6845727715293, 312.016...  \n",
       "2  (436.88235294117646, 208.28947368421052, 277.8...  \n",
       "3  (334.8421052631579, 324.51372549019607, 223.50...  \n",
       "4  (484.264, 457.71407185628743, 295.132997466478...  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_fitness['numerics'] = new_fitness['feature_name'].apply(lambda x: get_recency_attributes(x))\n",
    "new_fitness.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = new_fitness.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_name</th>\n",
       "      <th>avg_1</th>\n",
       "      <th>avg_0</th>\n",
       "      <th>sd_1</th>\n",
       "      <th>sd_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>recency__event_name__event_1</td>\n",
       "      <td>418.33673469387753</td>\n",
       "      <td>401.6289401836684</td>\n",
       "      <td>315.912321978574</td>\n",
       "      <td>308.19676698536676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>recency__event_name__event_2</td>\n",
       "      <td>336.0029239766082</td>\n",
       "      <td>312.6845727715293</td>\n",
       "      <td>312.0166271229759</td>\n",
       "      <td>300.3159893692403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>recency__event_name__event_3</td>\n",
       "      <td>436.88235294117646</td>\n",
       "      <td>208.28947368421052</td>\n",
       "      <td>277.86774784799627</td>\n",
       "      <td>267.17627786386157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>recency__event_name__event_4</td>\n",
       "      <td>334.8421052631579</td>\n",
       "      <td>324.51372549019607</td>\n",
       "      <td>223.50820595372997</td>\n",
       "      <td>310.86248891687404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>recency__event_name__event_5</td>\n",
       "      <td>484.264</td>\n",
       "      <td>457.71407185628743</td>\n",
       "      <td>295.1329974664784</td>\n",
       "      <td>321.8273778767297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   feature_name               avg_1                avg_0  \\\n",
       "0  recency__event_name__event_1  418.33673469387753    401.6289401836684   \n",
       "1  recency__event_name__event_2   336.0029239766082    312.6845727715293   \n",
       "2  recency__event_name__event_3  436.88235294117646   208.28947368421052   \n",
       "3  recency__event_name__event_4   334.8421052631579   324.51372549019607   \n",
       "4  recency__event_name__event_5             484.264   457.71407185628743   \n",
       "\n",
       "                  sd_1                 sd_0  \n",
       "0     315.912321978574   308.19676698536676  \n",
       "1    312.0166271229759    300.3159893692403  \n",
       "2   277.86774784799627   267.17627786386157  \n",
       "3   223.50820595372997   310.86248891687404  \n",
       "4    295.1329974664784    321.8273778767297  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.numerics = temp.numerics.astype('str').str.replace('(','')\n",
    "temp.numerics = temp.numerics.str.replace(')','')\n",
    "temp = pd.concat([temp, temp.numerics.str.split(',', expand=True)], axis=1)\n",
    "temp = temp.drop(['numerics'], axis=1)\n",
    "temp.columns = ['feature_name','avg_1','avg_0','sd_1','sd_0']\n",
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67\n",
      "12\n",
      "109\n",
      "49\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(768, 5)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(temp['avg_1'].str.contains('nan').sum())\n",
    "print(temp['avg_0'].str.contains('nan').sum())\n",
    "print(temp['sd_1'].str.contains('nan').sum())\n",
    "print(temp['sd_0'].str.contains('nan').sum())\n",
    "\n",
    "temp['avg_1'] = temp['avg_1'].str.replace('nan','0')\n",
    "temp['avg_0'] = temp['avg_0'].str.replace('nan','0')\n",
    "temp['sd_1'] = temp['sd_1'].str.replace('nan','0')\n",
    "temp['sd_0'] = temp['sd_0'].str.replace('nan','0')\n",
    "\n",
    "print(temp['avg_1'].str.contains('nan').sum())\n",
    "print(temp['avg_0'].str.contains('nan').sum())\n",
    "print(temp['sd_1'].str.contains('nan').sum())\n",
    "print(temp['sd_0'].str.contains('nan').sum())\n",
    "\n",
    "temp['avg_1'] = pd.to_numeric(temp['avg_1'])\n",
    "temp['avg_0'] = pd.to_numeric(temp['avg_0'])\n",
    "temp['sd_1'] = pd.to_numeric(temp['sd_1'])\n",
    "temp['sd_0'] = pd.to_numeric(temp['sd_0'])\n",
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frequency_attribute(event, value, times, data):\n",
    "    df = pd.DataFrame()\n",
    "    for time in times:\n",
    "        _data = data[(data[time_var]<=int(time))].reset_index(drop=True)\n",
    "        _freq = _data[[id_var, event, time_var]].groupby([id_var, event]).agg({time_var: len}).reset_index()\n",
    "        _freq.columns = [id_var, 'feature_name', 'feature_value']\n",
    "        _freq['feature_name'] = 'frequency__' + str(time) + '__' + event + '__' + _freq['feature_name'].astype(str)\n",
    "        _freq = _freq.reset_index(drop=True)\n",
    "        _df1 = pd.DataFrame(_freq['feature_name'].unique().tolist(), columns=['feature_name'])\n",
    "        _df2 = pd.DataFrame(_freq[id_var].unique().tolist(), columns=[id_var])\n",
    "        _df1['key'] = 1\n",
    "        _df2['key'] = 1\n",
    "        _freqTotal = pd.merge(_df2, _df1, on='key')\n",
    "        _freqTotal.drop(['key'], axis=1, inplace=True)\n",
    "        _freqTotal = pd.merge(_freqTotal, _freq, on=[id_var, 'feature_name'], how='left')\n",
    "        _freqTotal.fillna(0, inplace=True)\n",
    "        _df3 = data[[id_var,y_var]].drop_duplicates().reset_index(drop=True)\n",
    "        _freqTotal = _freqTotal.merge(_df3, on=id_var, how='left')\n",
    "        freqTotal = _freqTotal.copy()\n",
    "\n",
    "        group_1 = freqTotal.loc[freqTotal[y_var]==1,['feature_name', 'feature_value']].groupby('feature_name')\n",
    "        _avg1 = group_1.mean().reset_index()\n",
    "        _avg1.columns = ['feature_name', 'avg_1']\n",
    "        _sd1 = group_1.agg(np.std).reset_index()\n",
    "        _sd1.columns = ['feature_name', 'sd_1']\n",
    "        group_0 = freqTotal.loc[freqTotal[y_var]==0,['feature_name', 'feature_value']].groupby('feature_name')\n",
    "        _avg0 = group_0.mean().reset_index()\n",
    "        _avg0.columns = ['feature_name', 'avg_0']\n",
    "        _sd0 = group_0.agg(np.std).reset_index()\n",
    "        _sd0.columns = ['feature_name', 'sd_0']\n",
    "\n",
    "        _fitness_value = pd.merge(_avg1, _avg0, on='feature_name', how='left')\n",
    "        _fitness_value = pd.merge(_fitness_value, _sd1, on='feature_name', how='left')\n",
    "        _fitness_value = pd.merge(_fitness_value, _sd0, on='feature_name', how='left')\n",
    "        df = df.append(_fitness_value)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19488, 5)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_var = 'event_time'\n",
    "id_var = 'patient_id'\n",
    "y_var = 'outcome_flag'\n",
    "\n",
    "event = 'event_name'\n",
    "evalue = 'event_1'\n",
    "\n",
    "temp = temp.append(get_frequency_attribute(event, evalue, time0, df))\n",
    "\n",
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27615, 5)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event = 'specialty'\n",
    "evalue = 'spec_1'\n",
    "\n",
    "temp = temp.append(get_frequency_attribute(event, evalue, time0, df))\n",
    "\n",
    "event = 'plan_type'\n",
    "evalue = 'plan_type_1'\n",
    "\n",
    "temp = temp.append(get_frequency_attribute(event, evalue, time0, df))\n",
    "\n",
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp[['feature_name','avg_1','avg_0','sd_1','sd_0']].to_csv('fitness_values_train.csv',index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_norm_attributes(event, value, times, data):\n",
    "    df = pd.DataFrame()\n",
    "    for time in times:\n",
    "        _data_post = data[data[time_var]<=int(time)].reset_index(drop=True)\n",
    "        _data_pre = data[data[time_var]>int(time)].reset_index(drop=True)\n",
    "        _freq_post = _data_post[[id_var, event, time_var]].groupby([id_var, event]).agg({time_var: len}).reset_index()\n",
    "        _freq_pre = _data_pre[[id_var, event, time_var]].groupby([id_var, event]).agg({time_var: len}).reset_index()\n",
    "        _freq_post.columns = [id_var, 'feature_name', 'feature_value_post']\n",
    "        _freq_pre.columns = [id_var, 'feature_name', 'feature_value_pre']\n",
    "        _freq_post['feature_value_post'] = _freq_post['feature_value_post']/int(time)\n",
    "        _freq_pre['feature_value_pre'] = _freq_pre['feature_value_pre']/((data[time_var].max()) - int(time))\n",
    "        _normChange = pd.merge(_freq_post, _freq_pre, on=[id_var, 'feature_name'], how='outer')\n",
    "        _normChange.fillna(0, inplace=True)\n",
    "        _normChange['feature_value'] = np.where(_normChange['feature_value_post']>_normChange['feature_value_pre'], 1, 0)\n",
    "        _normChange.drop(['feature_value_post', 'feature_value_pre'], axis=1, inplace=True)\n",
    "        _normChange['feature_name'] = 'normChange__' + str(time) + '__' + event + '__' + _normChange['feature_name'].astype(str)\n",
    "\n",
    "        _normChange = _normChange.reset_index(drop=True)\n",
    "        _df1 = pd.DataFrame(_normChange['feature_name'].unique().tolist(), columns=['feature_name'])\n",
    "        _df2 = pd.DataFrame(_normChange[id_var].unique().tolist(), columns=[id_var])\n",
    "        _df1['key'] = 1\n",
    "        _df2['key'] = 1\n",
    "        _normTotal = pd.merge(_df2, _df1, on='key')\n",
    "        _normTotal.drop(['key'], axis=1, inplace=True)\n",
    "        _normTotal = pd.merge(_normTotal, _normChange, on=[id_var, 'feature_name'], how='left')\n",
    "        _normTotal.fillna(0, inplace=True)\n",
    "        _df3 = data[[id_var,y_var]].drop_duplicates().reset_index(drop=True)\n",
    "        _normTotal = _normTotal.merge(_df3, on=id_var, how='left')\n",
    "        normTotal = _normTotal.copy()\n",
    "\n",
    "        group_1 = normTotal.loc[normTotal[y_var]==1,['feature_name', 'feature_value']].groupby('feature_name')\n",
    "        _avg1 = group_1.mean().reset_index()\n",
    "        _avg1.columns = ['feature_name', 'avg_1']\n",
    "        _sd1 = group_1.agg(np.std).reset_index()\n",
    "        _sd1.columns = ['feature_name', 'sd_1']\n",
    "        group_0 = normTotal.loc[normTotal[y_var]==0,['feature_name', 'feature_value']].groupby('feature_name')\n",
    "        _avg0 = group_0.mean().reset_index()\n",
    "        _avg0.columns = ['feature_name', 'avg_0']\n",
    "        _sd0 = group_0.agg(np.std).reset_index()\n",
    "        _sd0.columns = ['feature_name', 'sd_0']\n",
    "\n",
    "        _fitness_value = pd.merge(_avg1, _avg0, on='feature_name', how='left')\n",
    "        _fitness_value = pd.merge(_fitness_value, _sd1, on='feature_name', how='left')\n",
    "        _fitness_value = pd.merge(_fitness_value, _sd0, on='feature_name', how='left')\n",
    "        df = df.append(_fitness_value)\n",
    "    return (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(41439, 5)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "event = 'event_name'\n",
    "evalue = 'event_1'\n",
    "\n",
    "temp = temp.append(get_norm_attributes(event, evalue, time1, df))\n",
    "\n",
    "event = 'specialty'\n",
    "evalue = 'spec_1'\n",
    "\n",
    "temp = temp.append(get_norm_attributes(event, evalue, time1, df))\n",
    "\n",
    "event = 'plan_type'\n",
    "evalue = 'plan_type_1'\n",
    "\n",
    "temp = temp.append(get_norm_attributes(event, evalue, time1, df))\n",
    "\n",
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fitness_calculation(data):\n",
    "    if ((data['sd_0'] == 0 ) and (data['sd_1'] == 0)) and (((data['avg_0'] == 0) and (data['avg_1'] != 0)) or ((data['avg_0'] != 0) and (data['avg_1'] == 0))):\n",
    "        return 9999999999\n",
    "    elif (((data['sd_0'] == 0 ) and (data['sd_1'] != 0)) or ((data['sd_0'] != 0) and (data['sd_1'] == 0))) and (data['avg_0'] == data['avg_1']):\n",
    "        return 1\n",
    "    elif ((data['sd_0'] != 0 ) and (data['sd_1'] != 0)) and (data['avg_0'] != 0):\n",
    "        return ((data['avg_1']/data['sd_1'])/(data['avg_0']/data['sd_0']))\n",
    "    elif ((data['sd_0'] != 0 ) and (data['sd_1'] != 0)) and ((data['avg_0'] == 0) and (data['avg_1'] != 0)):\n",
    "        return 9999999999\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_name</th>\n",
       "      <th>avg_1</th>\n",
       "      <th>avg_0</th>\n",
       "      <th>sd_1</th>\n",
       "      <th>sd_0</th>\n",
       "      <th>fitness_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>recency__event_name__event_1</td>\n",
       "      <td>418.336735</td>\n",
       "      <td>401.628940</td>\n",
       "      <td>315.912322</td>\n",
       "      <td>308.196767</td>\n",
       "      <td>1.016161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>recency__event_name__event_2</td>\n",
       "      <td>336.002924</td>\n",
       "      <td>312.684573</td>\n",
       "      <td>312.016627</td>\n",
       "      <td>300.315989</td>\n",
       "      <td>1.034278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>recency__event_name__event_3</td>\n",
       "      <td>436.882353</td>\n",
       "      <td>208.289474</td>\n",
       "      <td>277.867748</td>\n",
       "      <td>267.176278</td>\n",
       "      <td>2.016773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>recency__event_name__event_4</td>\n",
       "      <td>334.842105</td>\n",
       "      <td>324.513725</td>\n",
       "      <td>223.508206</td>\n",
       "      <td>310.862489</td>\n",
       "      <td>1.435099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>recency__event_name__event_5</td>\n",
       "      <td>484.264000</td>\n",
       "      <td>457.714072</td>\n",
       "      <td>295.132997</td>\n",
       "      <td>321.827378</td>\n",
       "      <td>1.153701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   feature_name       avg_1       avg_0        sd_1  \\\n",
       "0  recency__event_name__event_1  418.336735  401.628940  315.912322   \n",
       "1  recency__event_name__event_2  336.002924  312.684573  312.016627   \n",
       "2  recency__event_name__event_3  436.882353  208.289474  277.867748   \n",
       "3  recency__event_name__event_4  334.842105  324.513725  223.508206   \n",
       "4  recency__event_name__event_5  484.264000  457.714072  295.132997   \n",
       "\n",
       "         sd_0  fitness_value  \n",
       "0  308.196767       1.016161  \n",
       "1  300.315989       1.034278  \n",
       "2  267.176278       2.016773  \n",
       "3  310.862489       1.435099  \n",
       "4  321.827378       1.153701  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp['fitness_value'] = temp.apply(fitness_calculation, axis=1)\n",
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp[['feature_name','avg_0','avg_1','sd_0','sd_1','fitness_value']].to_csv('fitness_values.csv',index=False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
